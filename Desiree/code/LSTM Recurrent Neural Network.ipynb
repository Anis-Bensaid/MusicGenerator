{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import h5py\n",
    "from random import sample\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import LSTM, Embedding\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import backend as K\n",
    "from feature_funcs import *\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "with open(\"../data/Jigs.txt\") as my_file:\n",
    "    abc_text = my_file.read()\n",
    "\n",
    "# Cut out unnecessary backslashes\n",
    "abc_text = re.sub('\\\\\\\\+\\n', '\\n', abc_text)\n",
    "\n",
    "# Find starting index of the data we care about\n",
    "start_ind = abc_text.find(\"X:\")\n",
    "abc_text = abc_text[start_ind:]\n",
    "\n",
    "# Encode data\n",
    "num_to_char, char_to_num = create_dictionaries(abc_text)\n",
    "vocab_length = len(num_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min text length:  177\n",
      "Max text length:  1200\n",
      "Average text length:  301.5545722713864\n"
     ]
    }
   ],
   "source": [
    "songs = re.findall(r'(T:(?:.+\\n)+\\n+)X:', abc_text)\n",
    "\n",
    "song_texts = []\n",
    "\n",
    "for song in songs:\n",
    "    song_text = re.search(r'(P:.+|K:.+)', song, re.DOTALL)\n",
    "    song_texts.append(song_text[0])\n",
    "    \n",
    "# Get aggregate statistics about song texts\n",
    "print(\"Min text length: \", min([len(text) for text in song_texts]))\n",
    "print(\"Max text length: \", max([len(text) for text in song_texts]))\n",
    "print(\"Average text length: \", np.mean([len(text) for text in song_texts]))\n",
    "\n",
    "# Make sure all song texts are the same length\n",
    "song_texts = [text[:170] for text in song_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Metadata elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract titles\n",
    "titles = []\n",
    "\n",
    "for song in songs:\n",
    "    title = re.search(r'(T:.+\\n% Nottingham Music Database\\n)', song).group(1)\n",
    "    titles.append(title)\n",
    "    \n",
    "# Pad titles to same length\n",
    "max_length = max(len(title) for title in titles)\n",
    "titles = [title.ljust(max_length) for title in titles]\n",
    "\n",
    "\n",
    "# Extract authors\n",
    "authors = []\n",
    "\n",
    "for song in songs:\n",
    "    author = re.search(r'\\n(S:.+\\n)', song).group(1)\n",
    "    authors.append(author)\n",
    "    \n",
    "# Pad authors to same length\n",
    "max_length = max(len(author) for author in authors)\n",
    "authors = [author.ljust(max_length) for author in authors]\n",
    "\n",
    "\n",
    "# Extract meters\n",
    "meters = []\n",
    "\n",
    "for song in songs:\n",
    "    meter = re.search(r'(M:\\d/\\d\\n)', song).group(1)\n",
    "    meters.append(meter)\n",
    "\n",
    "    \n",
    "# Pad meters to same length\n",
    "max_length = max(len(meter) for meter in meters)\n",
    "meters = [meter.ljust(max_length) for meter in meters]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nums_list = encoder2(song_texts, char_to_num)\n",
    "\n",
    "title_nums = encoder2(titles, char_to_num)\n",
    "author_nums = encoder2(authors, char_to_num)\n",
    "meter_nums = encoder2(meters, char_to_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Compile LSTM (Model 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:<br /> https://benjamintseng.com/portfolio/nlp-pubmed-data-using-tensorflow-and-keras/ <br />\n",
    "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/<br />\n",
    "https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5  <br />\n",
    "https://github.com/aamini/introtodeeplearning/blob/master/lab1/Part2_Music_Generation.ipynb  <br /> https://medium.com/datadriveninvestor/music-generation-using-deep-learning-85010fb982e2 \n",
    "<br /> https://keras.io/examples/lstm_text_generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RNN\n",
    "Epoch: When the Neural Network sees all of the training data <br />\n",
    "Batch: Subset of the data <br />\n",
    "i.e. If you have 1000 data points, your batch size is 500 and you want 1 epoch, then the NN will do 2 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Builder1(song_text_nums, metadata_nums, str_length, vocab_size):\n",
    "    # Prepare data\n",
    "    if str_length+1 > len(song_text_nums[0]):\n",
    "        return \"Your string length is too long for the data.\"\n",
    "\n",
    "    # The x_values begin at the start of each song text and are str_length characters long;\n",
    "    # Concatenate these with the metadata at the beginning\n",
    "    # The y_values are one character after the end of the x_values\n",
    "    x_data = np.concatenate((metadata_nums[0], song_text_nums[0][0:str_length]))\n",
    "    y_data = [song_text_nums[0][str_length]]\n",
    "    \n",
    "    for ind, song in enumerate(song_text_nums[1:], start=1):\n",
    "        x_concat = np.concatenate((metadata_nums[i], np.array(song[0:str_length])))\n",
    "        x_data = np.vstack((x_data, x_concat))\n",
    "        y_data.append(song[str_length])\n",
    "\n",
    "    # Convert x and y data to tensors\n",
    "    x_train = to_categorical(x_data, num_classes=vocab_size)\n",
    "    y_train = to_categorical(y_data, num_classes=vocab_size)\n",
    "    \n",
    "    # Build NN\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.LSTM(128, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(vocab_length, activation='softmax'))\n",
    "    \n",
    "    return x_train, y_train, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, mod1 = LSTM_Builder1(text_nums_list[:train_ind], meter_nums, 160, vocab_length)\n",
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmsprop: Divide the learning rate for a weight by a running average of the\n",
    "# magnitues of the recent gradients for that weight\n",
    "mod1.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "# Using this file path, the model checkpoints will be saved with the epoch number \n",
    "# and the validation loss in the filename.\n",
    "weights_filepath = \"mod1_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"loss\", verbose=0,\n",
    "    save_best_only=True, mode=\"min\")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "mod1.fit(x_train, y_train, epochs=1000, batch_size=100, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get testing data\n",
    "test_nums = text_nums_list[train_ind:]\n",
    "meter_test = meter_nums[train_ind:]\n",
    "str_length = 160\n",
    "\n",
    "x_test = np.concatenate((meter_test[0], test_nums[0][0:str_length]))\n",
    "y_test = [test_nums[0][str_length]]\n",
    "\n",
    "# The x_values begin at the start of each song text and are str_length characters long;\n",
    "# Concatenate these with the metadata at the beginning\n",
    "# The y_values are one character after the end of the x_values    \n",
    "for ind, song in enumerate(test_nums[1:], start=1):\n",
    "    x_concat = np.concatenate((meter_test[ind], song[0:str_length]))\n",
    "    x_test = np.vstack((x_test, x_concat))\n",
    "    y_test.append(song[str_length])\n",
    "\n",
    "# Convert x and y data to tensors\n",
    "x_test = to_categorical(x_test, num_classes=vocab_length)\n",
    "y_test = to_categorical(y_test, num_classes=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(binary_matrix, dictionary):\n",
    "    '''Convert numeric list a text string.'''\n",
    "    text_list = []\n",
    "    \n",
    "    for row in binary_matrix:\n",
    "        max_ind = np.argmax(row)\n",
    "        text_list.append(dictionary[max_ind])\n",
    "    \n",
    "    return \"\".join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder2(pred_matrix, dictionary):\n",
    "    '''Convert numeric list a text string.'''\n",
    "    my_session = tf.Session()\n",
    "    \n",
    "    text_list = []\n",
    "    \n",
    "    samples = tf.random.categorical(pred_matrix, num_samples=1)\n",
    "    samples = tf.squeeze(samples, axis=-1)\n",
    "    vals = sess.run(samples)\n",
    "    \n",
    "    text_pred = \"\".join([dictionary[i] for i in vals])\n",
    "        \n",
    "    return text_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder1(predictions, num_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starter = x_test[0]\n",
    "len_starter = len(x_test[0])\n",
    "\n",
    "x_vals = np.reshape(starter, (1, starter.shape[0], starter.shape[1]))\n",
    "result = decoder(starter, num_to_char)\n",
    "seq_len = 200\n",
    "\n",
    "for i in range(1,seq_len):\n",
    "    prediction = mod2.predict(x_vals)\n",
    "    starter = np.vstack((starter, prediction))\n",
    "    starter = starter[1:1+len_starter,]\n",
    "    \n",
    "    x_vals = np.reshape(starter, (1, starter.shape[0], starter.shape[1]))\n",
    "    \n",
    "    text_prediction = decoder2(prediction, num_to_char)\n",
    "    result += text_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(predictions, num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1)\n",
    "sess.run(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = tfp.distributions.OneHotCategorical(probs=prediction)\n",
    "sample = tfp.distributions.Sample(dist)\n",
    "sample\n",
    "sess = tf.Session()\n",
    "vals = sess.run(sampled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & Compile LSTM (Model 2; using music21 attributes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../../Anis/data/jiggs.txt\", \"r\")\n",
    "raw_input = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Repertoir():\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        f = open(path, \"r\")\n",
    "        self.string = f.read()\n",
    "        self.handler = abcFormat.ABCHandler()\n",
    "        self.handler.process(self.string)\n",
    "        self.songs_handlers = self.handler.splitByReferenceNumber()\n",
    "        self.songs = {}\n",
    "        self.__process()\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.string\n",
    "    \n",
    "    \n",
    "    def __process(self):\n",
    "        for ref_number, handler in self.songs_handlers.items():\n",
    "            self.songs[ref_number] = Song(handler)\n",
    "            \n",
    "    def get_part_vocab(self):\n",
    "        tokens = []\n",
    "        for ref_number, song in self.songs.items():\n",
    "            tokens+= song.part\n",
    "        tokens = list(set(tokens))            \n",
    "        return tokens\n",
    "    \n",
    "    def get_metadata_vocab(self, key):\n",
    "        tokens = []\n",
    "        for ref_number, song in self.songs.items():\n",
    "            tokens+= [song.metadata[key]]\n",
    "        tokens = list(set(tokens))            \n",
    "        return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Song():\n",
    "    def __init__(self, handler):\n",
    "        self.handler = handler\n",
    "        self.metadata = {\n",
    "            'X':1,\n",
    "            'T':'Unknown',\n",
    "            'S':'Unknown',\n",
    "            'M':'none',\n",
    "            'L':'',\n",
    "            'Q':'',\n",
    "            'K':''\n",
    "        }\n",
    "        self.part = []\n",
    "        self.__process()\n",
    "        \n",
    "    def __process(self):\n",
    "        for token in self.handler.tokens:\n",
    "            meta_data_ended=False\n",
    "            if isinstance(token, abcFormat.ABCMetadata):\n",
    "                if token.tag in self.metadata.keys():\n",
    "                    if self.metadata[token.tag]=='' or not meta_data_ended:\n",
    "                        self.metadata[token.tag] = token.data\n",
    "                else:\n",
    "                    self.metadata[token.tag] = token.data\n",
    "            elif isinstance(token, abcFormat.ABCNote ) or isinstance(token, abcFormat.ABCBar):\n",
    "                meta_data_ended = True\n",
    "                self.part.append(token.src)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.to_abc()\n",
    "    \n",
    "    def to_abc(self):\n",
    "        output = ''\n",
    "        for key, value in self.metadata.items():\n",
    "            output+= key+':'+value+\"\\n\"\n",
    "        for note in self.part:\n",
    "            output+=note\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_idx_mappings(vocab):\n",
    "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "    idx2char = np.array(vocab)\n",
    "    return char2idx, idx2char\n",
    "\n",
    "def get_input_tensors(part, k, m, part_char2idx, k_char2idx, m_char2idx):\n",
    "    part_tensor = torch.tensor([part_char2idx[note] for note in part[0:-1]], dtype=torch.long)\n",
    "    k_tensor = torch.tensor([k_char2idx[k] for note in part[0:-1]], dtype=torch.long)\n",
    "    m_tensor = torch.tensor([m_char2idx[m] for note in part[0:-1]], dtype=torch.long)\n",
    "    return part_tensor, k_tensor, m_tensor,\n",
    "\n",
    "def get_target_tensor(part, part_char2idx):\n",
    "    target_tensor = torch.tensor([part_char2idx[note] for note in part[1:]], dtype=torch.long)\n",
    "    return target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:1\n",
      "T:A and D\n",
      "S:EF\n",
      "M:6/8\n",
      "L:\n",
      "Q:\n",
      "K:D\n",
      "P:B\n",
      "f|\"A\"eccc2f|\"A\"eccc2f|\"A\"eccc2f|\"Bm\"BcB\"E7\"B2f|\"A\"eccc2f|\"A\"eccc2c/2d/2|\"D\"efe\"E7\"dcB|[1\"A\"Acea2:|[2\"A\"Aceag=g||\"D\"f2fFdd|\"D\"AFAf2e/2f/2|\"G\"g2gecd|\"Em\"efd\"A7\"cBA|\"D\"f^efdcd|\"D\"AFAf=ef|\"G\"gfg\"A7\"ABc|[1\"D\"d3d2e:|[2\"D\"d3d2||\n"
     ]
    }
   ],
   "source": [
    "rep = Repertoir('../../Anis/data/jiggs.txt')\n",
    "print(str(rep.songs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_vocab = rep.get_part_vocab()\n",
    "m_vocab = rep.get_metadata_vocab('M')\n",
    "k_vocab = rep.get_metadata_vocab('K')\n",
    "\n",
    "part_vocab_size = len(part_vocab)\n",
    "k_vocab_size = len(k_vocab)\n",
    "m_vocab_size = len(m_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_char2idx, part_idx2char = generate_char_idx_mappings(part_vocab)\n",
    "k_char2idx, k_idx2char = generate_char_idx_mappings(k_vocab)\n",
    "m_char2idx, m_idx2char = generate_char_idx_mappings(m_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_len = 60\n",
    "num_songs = int(0.9*len(rep.songs))\n",
    "k_len = min([len(rep.songs[i].metadata['K']) for i in range(1,num_songs+1)])\n",
    "m_len = min([len(rep.songs[i].metadata['M']) for i in range(1,num_songs+1)])\n",
    "\n",
    "part_num_matrix = np.zeros((num_songs, part_len))\n",
    "y_vals = []\n",
    "k_num_matrix = np.zeros((num_songs, 1))\n",
    "m_num_matrix = np.zeros((num_songs, m_len))\n",
    "\n",
    "for i in range(1,num_songs+1):\n",
    "    song = rep.songs[i]\n",
    "    part_num_matrix[i-1,] = np.array([part_char2idx[song.part[0:part_len][j]] for j in range(len(song.part[0:part_len]))])\n",
    "    k_num_matrix[i-1,0] = [k_char2idx[song.metadata['K']]][0]\n",
    "    m_num_matrix[i-1,] = [m_char2idx[song.metadata['M']]]\n",
    "    y_vals.append(part_char2idx[song.part[part_len]])\n",
    "\n",
    "# Convert y_vals to one_hot_encoded vectors\n",
    "y_data = to_categorical(y_vals, num_classes=part_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build LSTM NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Builder2(lstm_dim, dropout_pct, batch_size,\n",
    "                  embedding_dim, seq_len,\n",
    "                  part_voc_size, k_voc_size, m_voc_size, \n",
    "                  part_num_matrix, k_num_matrix, m_num_matrix):\n",
    "    \n",
    "    voc_input = Input(shape=(part_num_matrix.shape[1],))\n",
    "    k_input = Input(shape=(k_num_matrix.shape[1],))\n",
    "    m_input = Input(shape=(m_num_matrix.shape[1],))\n",
    "    \n",
    "    voc_embedding = Embedding(part_voc_size, embedding_dim)(voc_input)\n",
    "    \n",
    "    lstm_out = LSTM(lstm_dim, dropout=dropout_pct)(voc_embedding)\n",
    "    \n",
    "    concat = Concatenate()([lstm_out, k_input, m_input])\n",
    "\n",
    "    output = Dense(part_voc_size, activation='softmax')(concat)\n",
    "    \n",
    "    model = Model(inputs=[voc_input, k_input, m_input], outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = LSTM_Builder2(256, 0.2, 100, \n",
    "                     128, 60,\n",
    "                     part_vocab_size, k_vocab_size, m_vocab_size,\n",
    "                     part_num_matrix, \n",
    "                     k_num_matrix, \n",
    "                     m_num_matrix)\n",
    "\n",
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://benjamintseng.com/portfolio/nlp-pubmed-data-using-tensorflow-and-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Builder3(lstm_dims, dropout_pct, batch_size,\n",
    "                  embedding_dim, seq_len,\n",
    "                  part_voc_size, k_voc_size, m_voc_size, \n",
    "                  part_num_matrix, k_num_matrix, m_num_matrix):\n",
    "    \n",
    "    voc_input = Input(shape=(part_num_matrix.shape[1],))\n",
    "    k_input = Input(shape=(k_num_matrix.shape[1],))\n",
    "    m_input = Input(shape=(m_num_matrix.shape[1],))\n",
    "    \n",
    "    voc_embedding = Embedding(part_voc_size, embedding_dim)(voc_input)\n",
    "    k_embedding = Embedding(k_voc_size, embedding_dim)(k_input)\n",
    "    m_embedding = Embedding(m_voc_size, embedding_dim)(m_input)\n",
    "    \n",
    "    concat = Concatenate(axis=1)([m_embedding, k_embedding, voc_embedding])\n",
    "    \n",
    "    lstm1 = LSTM(lstm_dims[0], dropout=dropout_pct, return_sequences=True)(concat)\n",
    "    lstm2 = LSTM(lstm_dims[1], dropout=dropout_pct, return_sequences=True)(lstm1)\n",
    "    lstm3 = LSTM(lstm_dims[2], dropout=dropout_pct)(lstm2)\n",
    "\n",
    "    output = Dense(part_voc_size, activation='softmax')(lstm3)\n",
    "    \n",
    "    model = Model(inputs=[voc_input, k_input, m_input], outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_48 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 60)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 3, 512)       1024        input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 1, 512)       5632        input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 60, 512)      565248      input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64, 512)      0           embedding_48[0][0]               \n",
      "                                                                 embedding_47[0][0]               \n",
      "                                                                 embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_49 (LSTM)                  (None, 64, 256)      787456      concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_50 (LSTM)                  (None, 64, 256)      525312      lstm_49[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_51 (LSTM)                  (None, 256)          525312      lstm_50[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1104)         283728      lstm_51[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,693,712\n",
      "Trainable params: 2,693,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod3 = LSTM_Builder3([256, 256, 256], 0.2, 100, \n",
    "                     512, 60,\n",
    "                     part_vocab_size, k_vocab_size, m_vocab_size,\n",
    "                     part_num_matrix, \n",
    "                     k_num_matrix, \n",
    "                     m_num_matrix)\n",
    "\n",
    "mod3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, baseline=0.9, patience=200)\n",
    "\n",
    "mod3.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "weights_filepath = \"mod3_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"val_accuracy\", verbose=0,\n",
    "    save_best_only=True, mode=\"max\")\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "# Using this file path, the model checkpoints will be saved with the epoch number \n",
    "# and the validation loss in the filename.\n",
    "weights_filepath = \"mod3_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"loss\", verbose=0,\n",
    "    save_best_only=True, mode=\"min\")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214 samples, validate on 92 samples\n",
      "Epoch 1/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 6.9284 - accuracy: 0.1308 - val_loss: 6.1045 - val_accuracy: 0.1413\n",
      "Epoch 2/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 5.4095 - accuracy: 0.1869 - val_loss: 4.9050 - val_accuracy: 0.1413\n",
      "Epoch 3/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 4.1635 - accuracy: 0.1869 - val_loss: 4.5746 - val_accuracy: 0.1413\n",
      "Epoch 4/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.7490 - accuracy: 0.1869 - val_loss: 4.5970 - val_accuracy: 0.1413\n",
      "Epoch 5/5000\n",
      "214/214 [==============================] - 4s 21ms/step - loss: 3.6036 - accuracy: 0.1869 - val_loss: 4.7057 - val_accuracy: 0.1413\n",
      "Epoch 6/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5699 - accuracy: 0.1869 - val_loss: 4.8184 - val_accuracy: 0.1413\n",
      "Epoch 7/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5431 - accuracy: 0.1869 - val_loss: 4.9180 - val_accuracy: 0.1413\n",
      "Epoch 8/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5307 - accuracy: 0.1869 - val_loss: 4.9790 - val_accuracy: 0.1413\n",
      "Epoch 9/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5308 - accuracy: 0.1869 - val_loss: 5.0087 - val_accuracy: 0.1413\n",
      "Epoch 10/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5347 - accuracy: 0.1869 - val_loss: 5.0419 - val_accuracy: 0.1413\n",
      "Epoch 11/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5355 - accuracy: 0.1869 - val_loss: 5.0587 - val_accuracy: 0.1413\n",
      "Epoch 12/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5299 - accuracy: 0.1869 - val_loss: 5.0682 - val_accuracy: 0.1413\n",
      "Epoch 13/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5336 - accuracy: 0.1869 - val_loss: 5.0894 - val_accuracy: 0.1413\n",
      "Epoch 14/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5256 - accuracy: 0.1869 - val_loss: 5.0788 - val_accuracy: 0.1413\n",
      "Epoch 15/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5209 - accuracy: 0.1869 - val_loss: 5.0993 - val_accuracy: 0.1413\n",
      "Epoch 16/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5308 - accuracy: 0.1869 - val_loss: 5.1089 - val_accuracy: 0.1413\n",
      "Epoch 17/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.5304 - accuracy: 0.1869 - val_loss: 5.1107 - val_accuracy: 0.1413\n",
      "Epoch 18/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.5295 - accuracy: 0.1869 - val_loss: 5.1064 - val_accuracy: 0.1413\n",
      "Epoch 19/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.5241 - accuracy: 0.1869 - val_loss: 5.1206 - val_accuracy: 0.1413\n",
      "Epoch 20/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.5260 - accuracy: 0.1869 - val_loss: 5.1531 - val_accuracy: 0.1413\n",
      "Epoch 21/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 3.5367 - accuracy: 0.1869 - val_loss: 5.1607 - val_accuracy: 0.1413\n",
      "Epoch 22/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 3.5253 - accuracy: 0.1869 - val_loss: 5.1531 - val_accuracy: 0.1413\n",
      "Epoch 23/5000\n",
      "214/214 [==============================] - 4s 21ms/step - loss: 3.5334 - accuracy: 0.1869 - val_loss: 5.1668 - val_accuracy: 0.1413\n",
      "Epoch 24/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5304 - accuracy: 0.1869 - val_loss: 5.1851 - val_accuracy: 0.1413\n",
      "Epoch 25/5000\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 3.5244 - accuracy: 0.1869 - val_loss: 5.1953 - val_accuracy: 0.1413\n",
      "Epoch 26/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5197 - accuracy: 0.1869 - val_loss: 5.2084 - val_accuracy: 0.1413\n",
      "Epoch 27/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5231 - accuracy: 0.1869 - val_loss: 5.2269 - val_accuracy: 0.1413\n",
      "Epoch 28/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5317 - accuracy: 0.1869 - val_loss: 5.2295 - val_accuracy: 0.1413\n",
      "Epoch 29/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5256 - accuracy: 0.1869 - val_loss: 5.2041 - val_accuracy: 0.1413\n",
      "Epoch 30/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5154 - accuracy: 0.1869 - val_loss: 5.2005 - val_accuracy: 0.1413\n",
      "Epoch 31/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5237 - accuracy: 0.1869 - val_loss: 5.2232 - val_accuracy: 0.1413\n",
      "Epoch 32/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 3.5288 - accuracy: 0.1869 - val_loss: 5.2189 - val_accuracy: 0.1413\n",
      "Epoch 33/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5232 - accuracy: 0.1869 - val_loss: 5.2291 - val_accuracy: 0.1413\n",
      "Epoch 34/5000\n",
      "214/214 [==============================] - 5s 21ms/step - loss: 3.5264 - accuracy: 0.1869 - val_loss: 5.2613 - val_accuracy: 0.1413\n",
      "Epoch 35/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5326 - accuracy: 0.1869 - val_loss: 5.2880 - val_accuracy: 0.1413\n",
      "Epoch 36/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 3.5291 - accuracy: 0.1869 - val_loss: 5.2791 - val_accuracy: 0.1413\n",
      "Epoch 37/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 3.5245 - accuracy: 0.1869 - val_loss: 5.2512 - val_accuracy: 0.1413\n",
      "Epoch 38/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5269 - accuracy: 0.1869 - val_loss: 5.2625 - val_accuracy: 0.1413\n",
      "Epoch 39/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5246 - accuracy: 0.1869 - val_loss: 5.2456 - val_accuracy: 0.1413\n",
      "Epoch 40/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5262 - accuracy: 0.1869 - val_loss: 5.2606 - val_accuracy: 0.1413\n",
      "Epoch 41/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5289 - accuracy: 0.1869 - val_loss: 5.2834 - val_accuracy: 0.1413\n",
      "Epoch 42/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5291 - accuracy: 0.1869 - val_loss: 5.3038 - val_accuracy: 0.1413\n",
      "Epoch 43/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5187 - accuracy: 0.1869 - val_loss: 5.3070 - val_accuracy: 0.1413\n",
      "Epoch 44/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5192 - accuracy: 0.1869 - val_loss: 5.3053 - val_accuracy: 0.1413\n",
      "Epoch 45/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5296 - accuracy: 0.1869 - val_loss: 5.2975 - val_accuracy: 0.1413\n",
      "Epoch 46/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5233 - accuracy: 0.1869 - val_loss: 5.3123 - val_accuracy: 0.1413\n",
      "Epoch 47/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5217 - accuracy: 0.1869 - val_loss: 5.3555 - val_accuracy: 0.1413\n",
      "Epoch 48/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5301 - accuracy: 0.1869 - val_loss: 5.3667 - val_accuracy: 0.1413\n",
      "Epoch 49/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5326 - accuracy: 0.1869 - val_loss: 5.3460 - val_accuracy: 0.1413\n",
      "Epoch 50/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5297 - accuracy: 0.1869 - val_loss: 5.3417 - val_accuracy: 0.1413\n",
      "Epoch 51/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5200 - accuracy: 0.1869 - val_loss: 5.3442 - val_accuracy: 0.1413\n",
      "Epoch 52/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5218 - accuracy: 0.1869 - val_loss: 5.3494 - val_accuracy: 0.1413\n",
      "Epoch 53/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5283 - accuracy: 0.1869 - val_loss: 5.3465 - val_accuracy: 0.1413\n",
      "Epoch 54/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5312 - accuracy: 0.1869 - val_loss: 5.3469 - val_accuracy: 0.1413\n",
      "Epoch 55/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5258 - accuracy: 0.1869 - val_loss: 5.3683 - val_accuracy: 0.1413\n",
      "Epoch 56/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5285 - accuracy: 0.1869 - val_loss: 5.3945 - val_accuracy: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5290 - accuracy: 0.1869 - val_loss: 5.3873 - val_accuracy: 0.1413\n",
      "Epoch 58/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5262 - accuracy: 0.1869 - val_loss: 5.3600 - val_accuracy: 0.1413\n",
      "Epoch 59/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5254 - accuracy: 0.1869 - val_loss: 5.3527 - val_accuracy: 0.1413\n",
      "Epoch 60/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5247 - accuracy: 0.1869 - val_loss: 5.3647 - val_accuracy: 0.1413\n",
      "Epoch 61/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5296 - accuracy: 0.1869 - val_loss: 5.3765 - val_accuracy: 0.1413\n",
      "Epoch 62/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5193 - accuracy: 0.1869 - val_loss: 5.3825 - val_accuracy: 0.1413\n",
      "Epoch 63/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5249 - accuracy: 0.1869 - val_loss: 5.3979 - val_accuracy: 0.1413\n",
      "Epoch 64/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5354 - accuracy: 0.1869 - val_loss: 5.4144 - val_accuracy: 0.1413\n",
      "Epoch 65/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5251 - accuracy: 0.1869 - val_loss: 5.3998 - val_accuracy: 0.1413\n",
      "Epoch 66/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5212 - accuracy: 0.1869 - val_loss: 5.3962 - val_accuracy: 0.1413\n",
      "Epoch 67/5000\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 3.5335 - accuracy: 0.1869 - val_loss: 5.3921 - val_accuracy: 0.1413\n",
      "Epoch 68/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5257 - accuracy: 0.1869 - val_loss: 5.3870 - val_accuracy: 0.1413\n",
      "Epoch 69/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5308 - accuracy: 0.1869 - val_loss: 5.3905 - val_accuracy: 0.1413\n",
      "Epoch 70/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5297 - accuracy: 0.1869 - val_loss: 5.3941 - val_accuracy: 0.1413\n",
      "Epoch 71/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5202 - accuracy: 0.1869 - val_loss: 5.4084 - val_accuracy: 0.1413\n",
      "Epoch 72/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5251 - accuracy: 0.1869 - val_loss: 5.4230 - val_accuracy: 0.1413\n",
      "Epoch 73/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5187 - accuracy: 0.1869 - val_loss: 5.4254 - val_accuracy: 0.1413\n",
      "Epoch 74/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5177 - accuracy: 0.1869 - val_loss: 5.4250 - val_accuracy: 0.1413\n",
      "Epoch 75/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5240 - accuracy: 0.1869 - val_loss: 5.4311 - val_accuracy: 0.1413\n",
      "Epoch 76/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5248 - accuracy: 0.1869 - val_loss: 5.4290 - val_accuracy: 0.1413\n",
      "Epoch 77/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5176 - accuracy: 0.1869 - val_loss: 5.4513 - val_accuracy: 0.1413\n",
      "Epoch 78/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5381 - accuracy: 0.1869 - val_loss: 5.4555 - val_accuracy: 0.1413\n",
      "Epoch 79/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5297 - accuracy: 0.1869 - val_loss: 5.4366 - val_accuracy: 0.1413\n",
      "Epoch 80/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5222 - accuracy: 0.1869 - val_loss: 5.4429 - val_accuracy: 0.1413\n",
      "Epoch 81/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5181 - accuracy: 0.1869 - val_loss: 5.4608 - val_accuracy: 0.1413\n",
      "Epoch 82/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5207 - accuracy: 0.1869 - val_loss: 5.4598 - val_accuracy: 0.1413\n",
      "Epoch 83/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5270 - accuracy: 0.1869 - val_loss: 5.4594 - val_accuracy: 0.1413\n",
      "Epoch 84/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5227 - accuracy: 0.1869 - val_loss: 5.4583 - val_accuracy: 0.1413\n",
      "Epoch 85/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5234 - accuracy: 0.1869 - val_loss: 5.4721 - val_accuracy: 0.1413\n",
      "Epoch 86/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5278 - accuracy: 0.1869 - val_loss: 5.4841 - val_accuracy: 0.1413\n",
      "Epoch 87/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5205 - accuracy: 0.1869 - val_loss: 5.4869 - val_accuracy: 0.1413\n",
      "Epoch 88/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5188 - accuracy: 0.1869 - val_loss: 5.4917 - val_accuracy: 0.1413\n",
      "Epoch 89/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5266 - accuracy: 0.1869 - val_loss: 5.4944 - val_accuracy: 0.1413\n",
      "Epoch 90/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5295 - accuracy: 0.1869 - val_loss: 5.5169 - val_accuracy: 0.1413\n",
      "Epoch 91/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5261 - accuracy: 0.1869 - val_loss: 5.5238 - val_accuracy: 0.1413\n",
      "Epoch 92/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5280 - accuracy: 0.1869 - val_loss: 5.5017 - val_accuracy: 0.1413\n",
      "Epoch 93/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5263 - accuracy: 0.1869 - val_loss: 5.4860 - val_accuracy: 0.1413\n",
      "Epoch 94/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5317 - accuracy: 0.1869 - val_loss: 5.5058 - val_accuracy: 0.1413\n",
      "Epoch 95/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5347 - accuracy: 0.1869 - val_loss: 5.5098 - val_accuracy: 0.1413\n",
      "Epoch 96/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5311 - accuracy: 0.1869 - val_loss: 5.4916 - val_accuracy: 0.1413\n",
      "Epoch 97/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5243 - accuracy: 0.1869 - val_loss: 5.4804 - val_accuracy: 0.1413\n",
      "Epoch 98/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5232 - accuracy: 0.1869 - val_loss: 5.4865 - val_accuracy: 0.1413\n",
      "Epoch 99/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5303 - accuracy: 0.1869 - val_loss: 5.5026 - val_accuracy: 0.1413\n",
      "Epoch 100/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5247 - accuracy: 0.1869 - val_loss: 5.5057 - val_accuracy: 0.1413\n",
      "Epoch 101/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5258 - accuracy: 0.1869 - val_loss: 5.5222 - val_accuracy: 0.1413\n",
      "Epoch 102/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5431 - accuracy: 0.1869 - val_loss: 5.5323 - val_accuracy: 0.1413\n",
      "Epoch 103/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5280 - accuracy: 0.1869 - val_loss: 5.5175 - val_accuracy: 0.1413\n",
      "Epoch 104/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5335 - accuracy: 0.1869 - val_loss: 5.5157 - val_accuracy: 0.1413\n",
      "Epoch 105/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5356 - accuracy: 0.1869 - val_loss: 5.5246 - val_accuracy: 0.1413\n",
      "Epoch 106/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5250 - accuracy: 0.1869 - val_loss: 5.5394 - val_accuracy: 0.1413\n",
      "Epoch 107/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5290 - accuracy: 0.1869 - val_loss: 5.5567 - val_accuracy: 0.1413\n",
      "Epoch 108/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5246 - accuracy: 0.1869 - val_loss: 5.5411 - val_accuracy: 0.1413\n",
      "Epoch 109/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5190 - accuracy: 0.1869 - val_loss: 5.5368 - val_accuracy: 0.1413\n",
      "Epoch 110/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5232 - accuracy: 0.1869 - val_loss: 5.5412 - val_accuracy: 0.1413\n",
      "Epoch 111/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5294 - accuracy: 0.1869 - val_loss: 5.5358 - val_accuracy: 0.1413\n",
      "Epoch 112/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5250 - accuracy: 0.1869 - val_loss: 5.5436 - val_accuracy: 0.1413\n",
      "Epoch 113/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5199 - accuracy: 0.1869 - val_loss: 5.5438 - val_accuracy: 0.1413\n",
      "Epoch 114/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5272 - accuracy: 0.1869 - val_loss: 5.5475 - val_accuracy: 0.1413\n",
      "Epoch 115/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5301 - accuracy: 0.1869 - val_loss: 5.5308 - val_accuracy: 0.1413\n",
      "Epoch 116/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5230 - accuracy: 0.1869 - val_loss: 5.5340 - val_accuracy: 0.1413\n",
      "Epoch 117/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5214 - accuracy: 0.1869 - val_loss: 5.5320 - val_accuracy: 0.1413\n",
      "Epoch 118/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5221 - accuracy: 0.1869 - val_loss: 5.5411 - val_accuracy: 0.1413\n",
      "Epoch 119/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5205 - accuracy: 0.1869 - val_loss: 5.5829 - val_accuracy: 0.1413\n",
      "Epoch 120/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5217 - accuracy: 0.1869 - val_loss: 5.5868 - val_accuracy: 0.1413\n",
      "Epoch 121/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5218 - accuracy: 0.1869 - val_loss: 5.5685 - val_accuracy: 0.1413\n",
      "Epoch 122/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5274 - accuracy: 0.1869 - val_loss: 5.5777 - val_accuracy: 0.1413\n",
      "Epoch 123/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5259 - accuracy: 0.1869 - val_loss: 5.5855 - val_accuracy: 0.1413\n",
      "Epoch 124/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5195 - accuracy: 0.1869 - val_loss: 5.5895 - val_accuracy: 0.1413\n",
      "Epoch 125/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5239 - accuracy: 0.1869 - val_loss: 5.5933 - val_accuracy: 0.1413\n",
      "Epoch 126/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5272 - accuracy: 0.1869 - val_loss: 5.5812 - val_accuracy: 0.1413\n",
      "Epoch 127/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5391 - accuracy: 0.1869 - val_loss: 5.5867 - val_accuracy: 0.1413\n",
      "Epoch 128/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5279 - accuracy: 0.1869 - val_loss: 5.6090 - val_accuracy: 0.1413\n",
      "Epoch 129/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5384 - accuracy: 0.1869 - val_loss: 5.6082 - val_accuracy: 0.1413\n",
      "Epoch 130/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5371 - accuracy: 0.1869 - val_loss: 5.5904 - val_accuracy: 0.1413\n",
      "Epoch 131/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5257 - accuracy: 0.1869 - val_loss: 5.5871 - val_accuracy: 0.1413\n",
      "Epoch 132/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5238 - accuracy: 0.1869 - val_loss: 5.5755 - val_accuracy: 0.1413\n",
      "Epoch 133/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5181 - accuracy: 0.1869 - val_loss: 5.5709 - val_accuracy: 0.1413\n",
      "Epoch 134/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5175 - accuracy: 0.1869 - val_loss: 5.5921 - val_accuracy: 0.1413\n",
      "Epoch 135/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5328 - accuracy: 0.1869 - val_loss: 5.6156 - val_accuracy: 0.1413\n",
      "Epoch 136/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5308 - accuracy: 0.1869 - val_loss: 5.6015 - val_accuracy: 0.1413\n",
      "Epoch 137/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5200 - accuracy: 0.1869 - val_loss: 5.6061 - val_accuracy: 0.1413\n",
      "Epoch 138/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5207 - accuracy: 0.1869 - val_loss: 5.6260 - val_accuracy: 0.1413\n",
      "Epoch 139/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5196 - accuracy: 0.1869 - val_loss: 5.6470 - val_accuracy: 0.1413\n",
      "Epoch 140/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5214 - accuracy: 0.1869 - val_loss: 5.6373 - val_accuracy: 0.1413\n",
      "Epoch 141/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5236 - accuracy: 0.1869 - val_loss: 5.6440 - val_accuracy: 0.1413\n",
      "Epoch 142/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5330 - accuracy: 0.1869 - val_loss: 5.6334 - val_accuracy: 0.1413\n",
      "Epoch 143/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5329 - accuracy: 0.1869 - val_loss: 5.6299 - val_accuracy: 0.1413\n",
      "Epoch 144/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5288 - accuracy: 0.1869 - val_loss: 5.6181 - val_accuracy: 0.1413\n",
      "Epoch 145/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5272 - accuracy: 0.1869 - val_loss: 5.5991 - val_accuracy: 0.1413\n",
      "Epoch 146/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5226 - accuracy: 0.1869 - val_loss: 5.6069 - val_accuracy: 0.1413\n",
      "Epoch 147/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5295 - accuracy: 0.1869 - val_loss: 5.6188 - val_accuracy: 0.1413\n",
      "Epoch 148/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5287 - accuracy: 0.1869 - val_loss: 5.6017 - val_accuracy: 0.1413\n",
      "Epoch 149/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5241 - accuracy: 0.1869 - val_loss: 5.6120 - val_accuracy: 0.1413\n",
      "Epoch 150/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5249 - accuracy: 0.1869 - val_loss: 5.6339 - val_accuracy: 0.1413\n",
      "Epoch 151/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5270 - accuracy: 0.1869 - val_loss: 5.6568 - val_accuracy: 0.1413\n",
      "Epoch 152/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5323 - accuracy: 0.1869 - val_loss: 5.6638 - val_accuracy: 0.1413\n",
      "Epoch 153/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5308 - accuracy: 0.1869 - val_loss: 5.6529 - val_accuracy: 0.1413\n",
      "Epoch 154/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5271 - accuracy: 0.1869 - val_loss: 5.6425 - val_accuracy: 0.1413\n",
      "Epoch 155/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5188 - accuracy: 0.1869 - val_loss: 5.6344 - val_accuracy: 0.1413\n",
      "Epoch 156/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5211 - accuracy: 0.1869 - val_loss: 5.6319 - val_accuracy: 0.1413\n",
      "Epoch 157/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5215 - accuracy: 0.1869 - val_loss: 5.6380 - val_accuracy: 0.1413\n",
      "Epoch 158/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 3.5300 - accuracy: 0.1869 - val_loss: 5.6422 - val_accuracy: 0.1413\n",
      "Epoch 159/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 3.5309 - accuracy: 0.1869 - val_loss: 5.6459 - val_accuracy: 0.1413\n",
      "Epoch 160/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5242 - accuracy: 0.1869 - val_loss: 5.6667 - val_accuracy: 0.1413\n",
      "Epoch 161/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5220 - accuracy: 0.1869 - val_loss: 5.6621 - val_accuracy: 0.1413\n",
      "Epoch 162/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5272 - accuracy: 0.1869 - val_loss: 5.6556 - val_accuracy: 0.1413\n",
      "Epoch 163/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5246 - accuracy: 0.1869 - val_loss: 5.6628 - val_accuracy: 0.1413\n",
      "Epoch 164/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5229 - accuracy: 0.1869 - val_loss: 5.6984 - val_accuracy: 0.1413\n",
      "Epoch 165/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5341 - accuracy: 0.1869 - val_loss: 5.6984 - val_accuracy: 0.1413\n",
      "Epoch 166/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5307 - accuracy: 0.1869 - val_loss: 5.6764 - val_accuracy: 0.1413\n",
      "Epoch 167/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5301 - accuracy: 0.1869 - val_loss: 5.6474 - val_accuracy: 0.1413\n",
      "Epoch 168/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5252 - accuracy: 0.1869 - val_loss: 5.6450 - val_accuracy: 0.1413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5195 - accuracy: 0.1869 - val_loss: 5.6515 - val_accuracy: 0.1413\n",
      "Epoch 170/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5265 - accuracy: 0.1869 - val_loss: 5.6334 - val_accuracy: 0.1413\n",
      "Epoch 171/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5208 - accuracy: 0.1869 - val_loss: 5.6456 - val_accuracy: 0.1413\n",
      "Epoch 172/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5331 - accuracy: 0.1869 - val_loss: 5.6865 - val_accuracy: 0.1413\n",
      "Epoch 173/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5201 - accuracy: 0.1869 - val_loss: 5.6384 - val_accuracy: 0.1413\n",
      "Epoch 174/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5181 - accuracy: 0.1869 - val_loss: 5.6375 - val_accuracy: 0.1413\n",
      "Epoch 175/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.5153 - accuracy: 0.1869 - val_loss: 5.6440 - val_accuracy: 0.1413\n",
      "Epoch 176/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.5076 - accuracy: 0.1869 - val_loss: 5.6205 - val_accuracy: 0.1413\n",
      "Epoch 177/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.4911 - accuracy: 0.1869 - val_loss: 5.6019 - val_accuracy: 0.1413\n",
      "Epoch 178/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.4721 - accuracy: 0.1869 - val_loss: 5.5392 - val_accuracy: 0.1413\n",
      "Epoch 179/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.4369 - accuracy: 0.1869 - val_loss: 5.4876 - val_accuracy: 0.1413\n",
      "Epoch 180/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.4092 - accuracy: 0.1869 - val_loss: 5.3985 - val_accuracy: 0.1413\n",
      "Epoch 181/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.3650 - accuracy: 0.2103 - val_loss: 5.3301 - val_accuracy: 0.1522\n",
      "Epoch 182/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.3135 - accuracy: 0.2243 - val_loss: 5.2415 - val_accuracy: 0.1630\n",
      "Epoch 183/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.2560 - accuracy: 0.2196 - val_loss: 5.2223 - val_accuracy: 0.0978\n",
      "Epoch 184/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 3.1961 - accuracy: 0.2477 - val_loss: 5.2318 - val_accuracy: 0.1196\n",
      "Epoch 185/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.1525 - accuracy: 0.2383 - val_loss: 5.1768 - val_accuracy: 0.1413\n",
      "Epoch 186/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.1111 - accuracy: 0.2336 - val_loss: 5.1794 - val_accuracy: 0.0870\n",
      "Epoch 187/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.0696 - accuracy: 0.2570 - val_loss: 5.1948 - val_accuracy: 0.1413\n",
      "Epoch 188/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.0092 - accuracy: 0.2664 - val_loss: 5.2302 - val_accuracy: 0.1087\n",
      "Epoch 189/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 3.0173 - accuracy: 0.2430 - val_loss: 5.2974 - val_accuracy: 0.0870\n",
      "Epoch 190/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.9640 - accuracy: 0.2430 - val_loss: 5.3275 - val_accuracy: 0.0978\n",
      "Epoch 191/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.8982 - accuracy: 0.2991 - val_loss: 5.4246 - val_accuracy: 0.1196\n",
      "Epoch 192/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.9149 - accuracy: 0.2477 - val_loss: 5.3721 - val_accuracy: 0.0870\n",
      "Epoch 193/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.8338 - accuracy: 0.2991 - val_loss: 5.4027 - val_accuracy: 0.1304\n",
      "Epoch 194/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.7652 - accuracy: 0.3084 - val_loss: 5.4477 - val_accuracy: 0.1087\n",
      "Epoch 195/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.7108 - accuracy: 0.3178 - val_loss: 5.4954 - val_accuracy: 0.1413\n",
      "Epoch 196/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.6702 - accuracy: 0.2850 - val_loss: 5.5076 - val_accuracy: 0.1413\n",
      "Epoch 197/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.6383 - accuracy: 0.3178 - val_loss: 5.5046 - val_accuracy: 0.1304\n",
      "Epoch 198/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.5950 - accuracy: 0.3364 - val_loss: 5.5339 - val_accuracy: 0.1304\n",
      "Epoch 199/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.5473 - accuracy: 0.3551 - val_loss: 5.6043 - val_accuracy: 0.0978\n",
      "Epoch 200/5000\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 2.5215 - accuracy: 0.3411 - val_loss: 5.6544 - val_accuracy: 0.1196\n",
      "Epoch 201/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.5033 - accuracy: 0.3318 - val_loss: 5.6740 - val_accuracy: 0.0978\n",
      "Epoch 202/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.4759 - accuracy: 0.3364 - val_loss: 5.6679 - val_accuracy: 0.0978\n",
      "Epoch 203/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.4370 - accuracy: 0.3551 - val_loss: 5.7508 - val_accuracy: 0.1087\n",
      "Epoch 204/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.4138 - accuracy: 0.3645 - val_loss: 5.7872 - val_accuracy: 0.1304\n",
      "Epoch 205/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.3866 - accuracy: 0.3785 - val_loss: 5.7855 - val_accuracy: 0.0978\n",
      "Epoch 206/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.3638 - accuracy: 0.3598 - val_loss: 5.8382 - val_accuracy: 0.0870\n",
      "Epoch 207/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.3493 - accuracy: 0.3598 - val_loss: 5.8274 - val_accuracy: 0.0761\n",
      "Epoch 208/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.3185 - accuracy: 0.3738 - val_loss: 5.8413 - val_accuracy: 0.1087\n",
      "Epoch 209/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.2860 - accuracy: 0.3785 - val_loss: 5.8617 - val_accuracy: 0.0761\n",
      "Epoch 210/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.2519 - accuracy: 0.4159 - val_loss: 5.8712 - val_accuracy: 0.0978\n",
      "Epoch 211/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.2399 - accuracy: 0.3879 - val_loss: 5.8918 - val_accuracy: 0.0978\n",
      "Epoch 212/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.2058 - accuracy: 0.4299 - val_loss: 5.9022 - val_accuracy: 0.1087\n",
      "Epoch 213/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.1822 - accuracy: 0.4065 - val_loss: 5.9298 - val_accuracy: 0.0978\n",
      "Epoch 214/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.1859 - accuracy: 0.4019 - val_loss: 5.9815 - val_accuracy: 0.0978\n",
      "Epoch 215/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.1518 - accuracy: 0.4393 - val_loss: 5.9440 - val_accuracy: 0.0870\n",
      "Epoch 216/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.1186 - accuracy: 0.4252 - val_loss: 5.9537 - val_accuracy: 0.0978\n",
      "Epoch 217/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.0868 - accuracy: 0.4159 - val_loss: 5.9673 - val_accuracy: 0.0978\n",
      "Epoch 218/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.0714 - accuracy: 0.4346 - val_loss: 6.0136 - val_accuracy: 0.0652\n",
      "Epoch 219/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 2.0559 - accuracy: 0.4439 - val_loss: 6.0081 - val_accuracy: 0.0761\n",
      "Epoch 220/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.0809 - accuracy: 0.4673 - val_loss: 6.0008 - val_accuracy: 0.0978\n",
      "Epoch 221/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 2.0073 - accuracy: 0.4533 - val_loss: 6.0409 - val_accuracy: 0.0870\n",
      "Epoch 222/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.9474 - accuracy: 0.4953 - val_loss: 6.0491 - val_accuracy: 0.1087\n",
      "Epoch 223/5000\n",
      "214/214 [==============================] - 3s 15ms/step - loss: 1.9266 - accuracy: 0.4766 - val_loss: 6.0815 - val_accuracy: 0.0978\n",
      "Epoch 224/5000\n",
      "214/214 [==============================] - 4s 19ms/step - loss: 1.8912 - accuracy: 0.4953 - val_loss: 6.0649 - val_accuracy: 0.0978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/5000\n",
      "214/214 [==============================] - 4s 20ms/step - loss: 1.8548 - accuracy: 0.5047 - val_loss: 6.1367 - val_accuracy: 0.0978\n",
      "Epoch 226/5000\n",
      "214/214 [==============================] - 5s 23ms/step - loss: 1.8331 - accuracy: 0.5280 - val_loss: 6.1673 - val_accuracy: 0.0978\n",
      "Epoch 227/5000\n",
      "214/214 [==============================] - 5s 25ms/step - loss: 1.8056 - accuracy: 0.5280 - val_loss: 6.1258 - val_accuracy: 0.0978\n",
      "Epoch 228/5000\n",
      "214/214 [==============================] - 4s 19ms/step - loss: 1.7837 - accuracy: 0.5187 - val_loss: 6.1188 - val_accuracy: 0.1087\n",
      "Epoch 229/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.7609 - accuracy: 0.5187 - val_loss: 6.2152 - val_accuracy: 0.0978\n",
      "Epoch 230/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.7472 - accuracy: 0.5093 - val_loss: 6.2262 - val_accuracy: 0.1087\n",
      "Epoch 231/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.7205 - accuracy: 0.5234 - val_loss: 6.2689 - val_accuracy: 0.1087\n",
      "Epoch 232/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.6709 - accuracy: 0.5327 - val_loss: 6.3155 - val_accuracy: 0.0870\n",
      "Epoch 233/5000\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 1.6639 - accuracy: 0.5467 - val_loss: 6.3197 - val_accuracy: 0.1087\n",
      "Epoch 234/5000\n",
      "214/214 [==============================] - 3s 16ms/step - loss: 1.6460 - accuracy: 0.5607 - val_loss: 6.3243 - val_accuracy: 0.1087\n",
      "Epoch 235/5000\n",
      "214/214 [==============================] - 4s 16ms/step - loss: 1.6149 - accuracy: 0.5701 - val_loss: 6.3919 - val_accuracy: 0.0870\n",
      "Epoch 236/5000\n",
      "214/214 [==============================] - 4s 17ms/step - loss: 1.5828 - accuracy: 0.5794 - val_loss: 6.3949 - val_accuracy: 0.1087\n",
      "Epoch 237/5000\n",
      "214/214 [==============================] - 4s 18ms/step - loss: 1.5987 - accuracy: 0.5748 - val_loss: 6.3739 - val_accuracy: 0.1087\n",
      "Epoch 238/5000\n",
      " 50/214 [======>.......................] - ETA: 2s - loss: 1.6289 - accuracy: 0.5200"
     ]
    }
   ],
   "source": [
    "mod3.fit([part_num_matrix, k_num_matrix, m_num_matrix],\n",
    "         y_data, \n",
    "         epochs=5000, batch_size=50, shuffle=True, \n",
    "         validation_split=0.3,\n",
    "         callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up testing data\n",
    "my_session = tf.Session()\n",
    "mod3.reset_states()\n",
    "\n",
    "starter = rep.songs[num_songs]\n",
    "start_ind = int(0.9*len(rep.songs))\n",
    "end_ind = len(rep.songs)\n",
    "seq_len = 60\n",
    "\n",
    "input_part = np.zeros((1, part_len))\n",
    "sequences = input_part\n",
    "input_k = np.zeros((1, 1))\n",
    "input_m = np.zeros((1, m_len))\n",
    "\n",
    "for i in range(start_ind,start_ind+1):\n",
    "    song = rep.songs[i]\n",
    "    input_part[i-start_ind,] = np.array([part_char2idx[song.part[0:part_len][j]] for j in range(len(song.part[0:part_len]))])\n",
    "    input_k[i-start_ind,0] = [k_char2idx[song.metadata['K']]][0]\n",
    "    input_m[i-start_ind,] = [m_char2idx[song.metadata['M']]]\n",
    "\n",
    "# Starting string:\n",
    "beginning = str(rep.songs[start_ind])\n",
    "result = []\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "for i in range(seq_len):\n",
    "    prediction = mod3.predict([input_part, input_k, input_m])\n",
    "    \n",
    "    # Sample from output of probabilities\n",
    "    sample = tf.random.categorical(prediction, num_samples=1)\n",
    "    sample = tf.squeeze(sample, axis=-1)\n",
    "    numeric_pred = my_session.run(sample)[0]\n",
    "    \n",
    "    # Pass the prediction, along with the hidden state, back to the model\n",
    "    sequences = np.append(sequences, numeric_pred)\n",
    "    input_part = sequences[i:part_len+i].reshape(1, part_len)\n",
    "    \n",
    "    # Text predictions\n",
    "    text_val = part_idx2char[numeric_pred]\n",
    "    result.append(text_val)\n",
    "\n",
    "result = \"\".join(result)\n",
    "print(beginning)\n",
    "print(\"______\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: music21 attributes in single character encoding) <br />\n",
    "Sources: https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "jig_rep = Repertoir('../data/Jigs.txt')\n",
    "\n",
    "num_to_char, char_to_num = create_dictionaries(str(jig_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(num_to_char)\n",
    "\n",
    "num_songs = int(0.9*len(jig_rep.songs))\n",
    "total_songs = len(jig_rep.songs)\n",
    "\n",
    "part_len = min(len(list(\"\".join(jig_rep.songs[i].part))) for i in range(1,total_songs+1)) - 2\n",
    "k_len = min([len(list(jig_rep.songs[i].metadata['K'])) for i in range(1,total_songs+1)])\n",
    "m_len = min([len(list(jig_rep.songs[i].metadata['M'])) for i in range(1,total_songs+1)])\n",
    "\n",
    "part_num_matrix = np.zeros((num_songs, part_len))\n",
    "y_vals = []\n",
    "k_num_matrix = np.zeros((num_songs, k_len))\n",
    "m_num_matrix = np.zeros((num_songs, m_len))\n",
    "\n",
    "for i in range(1,num_songs+1):\n",
    "    song = jig_rep.songs[i]\n",
    "    part_string = \"\".join(song.part)\n",
    "    part_num_matrix[i-1,] = np.array([char_to_num[part_string[0:part_len][j]] for j in range(part_len)])\n",
    "    \n",
    "    k_string = \"\".join(song.metadata['K'])\n",
    "    k_num_matrix[i-1,0] = np.array([char_to_num[k_string[j]] for j in range(k_len)])\n",
    "    \n",
    "    m_string = \"\".join(song.metadata['M'])\n",
    "    m_num_matrix[i-1,] = np.array([char_to_num[m_string[j]] for j in range(m_len)])\n",
    "    \n",
    "    y_vals.append(char_to_num[part_string[part_len]])\n",
    "\n",
    "# Convert y_vals to one_hot_encoded vectors\n",
    "y_data = to_categorical(y_vals, num_classes=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((306, 150), (306, 1), (306, 3))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_num_matrix.shape, k_num_matrix.shape, m_num_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Builder4(lstm_dims, dropout_pct, batch_size,\n",
    "                  embedding_dim,\n",
    "                  vocab_size, \n",
    "                  part_num_matrix, k_num_matrix, m_num_matrix):\n",
    "    \n",
    "    voc_input = Input(shape=(part_num_matrix.shape[1],))\n",
    "    k_input = Input(shape=(k_num_matrix.shape[1],))\n",
    "    m_input = Input(shape=(m_num_matrix.shape[1],))\n",
    "    \n",
    "    voc_embedding = Embedding(vocab_size, embedding_dim)(voc_input)\n",
    "    k_embedding = Embedding(vocab_size, embedding_dim)(k_input)\n",
    "    m_embedding = Embedding(vocab_size, embedding_dim)(m_input)\n",
    "    \n",
    "    concat = Concatenate(axis=1)([m_embedding, k_embedding, voc_embedding])\n",
    "    \n",
    "    lstm1 = LSTM(lstm_dims[0], dropout=dropout_pct, return_sequences=True)(concat)\n",
    "    lstm2 = LSTM(lstm_dims[1], dropout=dropout_pct, return_sequences=True)(lstm1)\n",
    "    lstm3 = LSTM(lstm_dims[2], dropout=dropout_pct)(lstm2)\n",
    "\n",
    "    output = Dense(vocab_size, activation='softmax')(lstm3)\n",
    "    \n",
    "    model = Model(inputs=[voc_input, k_input, m_input], outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 150)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_39 (Embedding)        (None, 3, 87)        7569        input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 1, 87)        7569        input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 150, 87)      7569        input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 154, 87)      0           embedding_39[0][0]               \n",
      "                                                                 embedding_38[0][0]               \n",
      "                                                                 embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 154, 256)     352256      concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 154, 256)     525312      lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 256)          525312      lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 87)           22359       lstm_36[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,447,946\n",
      "Trainable params: 1,447,946\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod4 = LSTM_Builder4([256, 256, 256], 0.2, 50, \n",
    "                     vocab_length,\n",
    "                     vocab_length,\n",
    "                     part_num_matrix, k_num_matrix, m_num_matrix)\n",
    "\n",
    "mod4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, baseline=0.9, patience=200)\n",
    "\n",
    "mod4.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "weights_filepath = \"mod4_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"val_accuracy\", verbose=0,\n",
    "    save_best_only=True, mode=\"max\")\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214 samples, validate on 92 samples\n",
      "Epoch 1/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 4.3682 - accuracy: 0.0794 - val_loss: 3.1809 - val_accuracy: 0.2283\n",
      "Epoch 2/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 3.2808 - accuracy: 0.1449 - val_loss: 2.8825 - val_accuracy: 0.1304\n",
      "Epoch 3/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 3.0597 - accuracy: 0.1121 - val_loss: 2.8660 - val_accuracy: 0.2283\n",
      "Epoch 4/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.9790 - accuracy: 0.1449 - val_loss: 2.8277 - val_accuracy: 0.2283\n",
      "Epoch 5/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 2.9120 - accuracy: 0.1449 - val_loss: 2.7295 - val_accuracy: 0.2283\n",
      "Epoch 6/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8992 - accuracy: 0.1215 - val_loss: 2.6985 - val_accuracy: 0.2283\n",
      "Epoch 7/5000\n",
      "214/214 [==============================] - 7s 35ms/step - loss: 2.8882 - accuracy: 0.1449 - val_loss: 2.7434 - val_accuracy: 0.2283\n",
      "Epoch 8/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8982 - accuracy: 0.1449 - val_loss: 2.7734 - val_accuracy: 0.2283\n",
      "Epoch 9/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8756 - accuracy: 0.1449 - val_loss: 2.7538 - val_accuracy: 0.2283\n",
      "Epoch 10/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8856 - accuracy: 0.1308 - val_loss: 2.7174 - val_accuracy: 0.2283\n",
      "Epoch 11/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.8813 - accuracy: 0.1449 - val_loss: 2.7023 - val_accuracy: 0.2283\n",
      "Epoch 12/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8826 - accuracy: 0.1449 - val_loss: 2.7090 - val_accuracy: 0.2283\n",
      "Epoch 13/5000\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 2.8729 - accuracy: 0.1449 - val_loss: 2.7399 - val_accuracy: 0.2283\n",
      "Epoch 14/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8805 - accuracy: 0.0981 - val_loss: 2.7777 - val_accuracy: 0.2283\n",
      "Epoch 15/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8756 - accuracy: 0.0794 - val_loss: 2.7442 - val_accuracy: 0.2283\n",
      "Epoch 16/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8776 - accuracy: 0.1308 - val_loss: 2.7354 - val_accuracy: 0.2283\n",
      "Epoch 17/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8705 - accuracy: 0.1449 - val_loss: 2.7303 - val_accuracy: 0.2283\n",
      "Epoch 18/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8842 - accuracy: 0.1449 - val_loss: 2.7364 - val_accuracy: 0.2283\n",
      "Epoch 19/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8730 - accuracy: 0.1449 - val_loss: 2.7339 - val_accuracy: 0.2283\n",
      "Epoch 20/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8650 - accuracy: 0.1449 - val_loss: 2.7073 - val_accuracy: 0.2283\n",
      "Epoch 21/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8601 - accuracy: 0.1449 - val_loss: 2.7166 - val_accuracy: 0.2283\n",
      "Epoch 22/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8700 - accuracy: 0.1449 - val_loss: 2.7412 - val_accuracy: 0.2283\n",
      "Epoch 23/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 2.8647 - accuracy: 0.1449 - val_loss: 2.7240 - val_accuracy: 0.2283\n",
      "Epoch 24/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8639 - accuracy: 0.1449 - val_loss: 2.7290 - val_accuracy: 0.2283\n",
      "Epoch 25/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8702 - accuracy: 0.1449 - val_loss: 2.7453 - val_accuracy: 0.2283\n",
      "Epoch 26/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8762 - accuracy: 0.1402 - val_loss: 2.7455 - val_accuracy: 0.2283\n",
      "Epoch 27/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8682 - accuracy: 0.1449 - val_loss: 2.7050 - val_accuracy: 0.2283\n",
      "Epoch 28/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8655 - accuracy: 0.1449 - val_loss: 2.7260 - val_accuracy: 0.2283\n",
      "Epoch 29/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8618 - accuracy: 0.1449 - val_loss: 2.7339 - val_accuracy: 0.2283\n",
      "Epoch 30/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8700 - accuracy: 0.1449 - val_loss: 2.7212 - val_accuracy: 0.2283\n",
      "Epoch 31/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8616 - accuracy: 0.1449 - val_loss: 2.7064 - val_accuracy: 0.2283\n",
      "Epoch 32/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8780 - accuracy: 0.1495 - val_loss: 2.6959 - val_accuracy: 0.2283\n",
      "Epoch 33/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8631 - accuracy: 0.1449 - val_loss: 2.7047 - val_accuracy: 0.2283\n",
      "Epoch 34/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8643 - accuracy: 0.1449 - val_loss: 2.7185 - val_accuracy: 0.2283\n",
      "Epoch 35/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8668 - accuracy: 0.1449 - val_loss: 2.7367 - val_accuracy: 0.2283\n",
      "Epoch 36/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8666 - accuracy: 0.1449 - val_loss: 2.7220 - val_accuracy: 0.2283\n",
      "Epoch 37/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8625 - accuracy: 0.1449 - val_loss: 2.7297 - val_accuracy: 0.2283\n",
      "Epoch 38/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8652 - accuracy: 0.1449 - val_loss: 2.7423 - val_accuracy: 0.2283\n",
      "Epoch 39/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8628 - accuracy: 0.1449 - val_loss: 2.7472 - val_accuracy: 0.2283\n",
      "Epoch 40/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8627 - accuracy: 0.1449 - val_loss: 2.7325 - val_accuracy: 0.2283\n",
      "Epoch 41/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8652 - accuracy: 0.1449 - val_loss: 2.7213 - val_accuracy: 0.1304\n",
      "Epoch 42/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8817 - accuracy: 0.0935 - val_loss: 2.7147 - val_accuracy: 0.2283\n",
      "Epoch 43/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8680 - accuracy: 0.1449 - val_loss: 2.7080 - val_accuracy: 0.2283\n",
      "Epoch 44/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8724 - accuracy: 0.1449 - val_loss: 2.7369 - val_accuracy: 0.2283\n",
      "Epoch 45/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8750 - accuracy: 0.1449 - val_loss: 2.7290 - val_accuracy: 0.2283\n",
      "Epoch 46/5000\n",
      "214/214 [==============================] - 8s 35ms/step - loss: 2.8624 - accuracy: 0.1449 - val_loss: 2.7360 - val_accuracy: 0.2283\n",
      "Epoch 47/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.8645 - accuracy: 0.1308 - val_loss: 2.7187 - val_accuracy: 0.2283\n",
      "Epoch 48/5000\n",
      "214/214 [==============================] - 7s 30ms/step - loss: 2.8602 - accuracy: 0.1402 - val_loss: 2.7246 - val_accuracy: 0.2283\n",
      "Epoch 49/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8680 - accuracy: 0.1449 - val_loss: 2.7226 - val_accuracy: 0.2283\n",
      "Epoch 50/5000\n",
      "214/214 [==============================] - 7s 30ms/step - loss: 2.8758 - accuracy: 0.1449 - val_loss: 2.6920 - val_accuracy: 0.2283\n",
      "Epoch 51/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.8610 - accuracy: 0.1449 - val_loss: 2.6841 - val_accuracy: 0.2283\n",
      "Epoch 52/5000\n",
      "214/214 [==============================] - 8s 35ms/step - loss: 2.8620 - accuracy: 0.1449 - val_loss: 2.7273 - val_accuracy: 0.2283\n",
      "Epoch 53/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8607 - accuracy: 0.1449 - val_loss: 2.7555 - val_accuracy: 0.2283\n",
      "Epoch 54/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.8592 - accuracy: 0.1449 - val_loss: 2.7656 - val_accuracy: 0.2283\n",
      "Epoch 55/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8587 - accuracy: 0.1449 - val_loss: 2.7300 - val_accuracy: 0.2283\n",
      "Epoch 56/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 2.8686 - accuracy: 0.1449 - val_loss: 2.7170 - val_accuracy: 0.2283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8607 - accuracy: 0.1449 - val_loss: 2.7267 - val_accuracy: 0.2283\n",
      "Epoch 58/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.8603 - accuracy: 0.1449 - val_loss: 2.7209 - val_accuracy: 0.2283\n",
      "Epoch 59/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8519 - accuracy: 0.1449 - val_loss: 2.7228 - val_accuracy: 0.2283\n",
      "Epoch 60/5000\n",
      "214/214 [==============================] - 6s 29ms/step - loss: 2.8523 - accuracy: 0.1449 - val_loss: 2.7071 - val_accuracy: 0.2283\n",
      "Epoch 61/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.8471 - accuracy: 0.1449 - val_loss: 2.7164 - val_accuracy: 0.2283\n",
      "Epoch 62/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 2.8401 - accuracy: 0.1449 - val_loss: 2.7139 - val_accuracy: 0.2283\n",
      "Epoch 63/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 2.8391 - accuracy: 0.1449 - val_loss: 2.7086 - val_accuracy: 0.2283\n",
      "Epoch 64/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.8291 - accuracy: 0.1449 - val_loss: 2.6696 - val_accuracy: 0.2283\n",
      "Epoch 65/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 2.8100 - accuracy: 0.1449 - val_loss: 2.6388 - val_accuracy: 0.2283\n",
      "Epoch 66/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 2.7830 - accuracy: 0.1495 - val_loss: 2.6140 - val_accuracy: 0.2609\n",
      "Epoch 67/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.7622 - accuracy: 0.2009 - val_loss: 2.5814 - val_accuracy: 0.2609\n",
      "Epoch 68/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.7218 - accuracy: 0.2056 - val_loss: 2.5314 - val_accuracy: 0.2826\n",
      "Epoch 69/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.6817 - accuracy: 0.2103 - val_loss: 2.5000 - val_accuracy: 0.2935\n",
      "Epoch 70/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 2.6383 - accuracy: 0.1963 - val_loss: 2.4703 - val_accuracy: 0.2935\n",
      "Epoch 71/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.5673 - accuracy: 0.2103 - val_loss: 2.4182 - val_accuracy: 0.2935\n",
      "Epoch 72/5000\n",
      "214/214 [==============================] - 8s 35ms/step - loss: 2.5288 - accuracy: 0.1963 - val_loss: 2.3953 - val_accuracy: 0.2935\n",
      "Epoch 73/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.5070 - accuracy: 0.2290 - val_loss: 2.3989 - val_accuracy: 0.3043\n",
      "Epoch 74/5000\n",
      "214/214 [==============================] - 8s 35ms/step - loss: 2.4777 - accuracy: 0.2336 - val_loss: 2.3751 - val_accuracy: 0.2826\n",
      "Epoch 75/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.4377 - accuracy: 0.2336 - val_loss: 2.3909 - val_accuracy: 0.3370\n",
      "Epoch 76/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.4290 - accuracy: 0.2523 - val_loss: 2.3494 - val_accuracy: 0.3478\n",
      "Epoch 77/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.3841 - accuracy: 0.2850 - val_loss: 2.3068 - val_accuracy: 0.2935\n",
      "Epoch 78/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.3650 - accuracy: 0.2897 - val_loss: 2.2844 - val_accuracy: 0.3587\n",
      "Epoch 79/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.3274 - accuracy: 0.2944 - val_loss: 2.2481 - val_accuracy: 0.3587\n",
      "Epoch 80/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.3015 - accuracy: 0.2710 - val_loss: 2.2421 - val_accuracy: 0.3478\n",
      "Epoch 81/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.2941 - accuracy: 0.2850 - val_loss: 2.2393 - val_accuracy: 0.3587\n",
      "Epoch 82/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 2.2581 - accuracy: 0.3271 - val_loss: 2.2370 - val_accuracy: 0.3261\n",
      "Epoch 83/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.2399 - accuracy: 0.3318 - val_loss: 2.2111 - val_accuracy: 0.3913\n",
      "Epoch 84/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 2.2107 - accuracy: 0.3458 - val_loss: 2.1410 - val_accuracy: 0.4022\n",
      "Epoch 85/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.1851 - accuracy: 0.3551 - val_loss: 2.1532 - val_accuracy: 0.3587\n",
      "Epoch 86/5000\n",
      "214/214 [==============================] - 7s 35ms/step - loss: 2.1703 - accuracy: 0.3224 - val_loss: 2.1851 - val_accuracy: 0.3696\n",
      "Epoch 87/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.1505 - accuracy: 0.3598 - val_loss: 2.1678 - val_accuracy: 0.3804\n",
      "Epoch 88/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 2.1234 - accuracy: 0.3598 - val_loss: 2.1734 - val_accuracy: 0.3696\n",
      "Epoch 89/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.1071 - accuracy: 0.3645 - val_loss: 2.2041 - val_accuracy: 0.3696\n",
      "Epoch 90/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 2.0652 - accuracy: 0.3598 - val_loss: 2.1624 - val_accuracy: 0.3370\n",
      "Epoch 91/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 2.0095 - accuracy: 0.3832 - val_loss: 2.1687 - val_accuracy: 0.3804\n",
      "Epoch 92/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 1.9987 - accuracy: 0.3925 - val_loss: 2.1636 - val_accuracy: 0.3696\n",
      "Epoch 93/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.9713 - accuracy: 0.3738 - val_loss: 2.1264 - val_accuracy: 0.3696\n",
      "Epoch 94/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.9594 - accuracy: 0.3505 - val_loss: 2.1364 - val_accuracy: 0.3261\n",
      "Epoch 95/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.9440 - accuracy: 0.3972 - val_loss: 2.2062 - val_accuracy: 0.3043\n",
      "Epoch 96/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.9104 - accuracy: 0.4019 - val_loss: 2.1828 - val_accuracy: 0.3370\n",
      "Epoch 97/5000\n",
      "214/214 [==============================] - 8s 35ms/step - loss: 1.8611 - accuracy: 0.4019 - val_loss: 2.2257 - val_accuracy: 0.3370\n",
      "Epoch 98/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.8398 - accuracy: 0.4206 - val_loss: 2.2044 - val_accuracy: 0.3261\n",
      "Epoch 99/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.8197 - accuracy: 0.3879 - val_loss: 2.2114 - val_accuracy: 0.3478\n",
      "Epoch 100/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.8061 - accuracy: 0.4112 - val_loss: 2.1913 - val_accuracy: 0.3587\n",
      "Epoch 101/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.8114 - accuracy: 0.3879 - val_loss: 2.2392 - val_accuracy: 0.3478\n",
      "Epoch 102/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.7968 - accuracy: 0.3832 - val_loss: 2.2772 - val_accuracy: 0.3370\n",
      "Epoch 103/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 1.7713 - accuracy: 0.4206 - val_loss: 2.2370 - val_accuracy: 0.3261\n",
      "Epoch 104/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.7286 - accuracy: 0.4533 - val_loss: 2.2255 - val_accuracy: 0.3370\n",
      "Epoch 105/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 1.6868 - accuracy: 0.4486 - val_loss: 2.2374 - val_accuracy: 0.3478\n",
      "Epoch 106/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.6675 - accuracy: 0.4252 - val_loss: 2.2932 - val_accuracy: 0.3261\n",
      "Epoch 107/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 1.6566 - accuracy: 0.4439 - val_loss: 2.2888 - val_accuracy: 0.3152\n",
      "Epoch 108/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.6147 - accuracy: 0.4626 - val_loss: 2.2488 - val_accuracy: 0.3261\n",
      "Epoch 109/5000\n",
      "214/214 [==============================] - 6s 30ms/step - loss: 1.5875 - accuracy: 0.4766 - val_loss: 2.3047 - val_accuracy: 0.3261\n",
      "Epoch 110/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 1.5781 - accuracy: 0.4486 - val_loss: 2.3020 - val_accuracy: 0.3152\n",
      "Epoch 111/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 1.5105 - accuracy: 0.4860 - val_loss: 2.3409 - val_accuracy: 0.3261\n",
      "Epoch 112/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 1.4828 - accuracy: 0.5000 - val_loss: 2.3406 - val_accuracy: 0.3587\n",
      "Epoch 113/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 7s 35ms/step - loss: 1.4707 - accuracy: 0.5280 - val_loss: 2.3820 - val_accuracy: 0.3370\n",
      "Epoch 114/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.4720 - accuracy: 0.5093 - val_loss: 2.3184 - val_accuracy: 0.3478\n",
      "Epoch 115/5000\n",
      "214/214 [==============================] - 7s 35ms/step - loss: 1.4342 - accuracy: 0.5234 - val_loss: 2.3600 - val_accuracy: 0.3804\n",
      "Epoch 116/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 1.3917 - accuracy: 0.5327 - val_loss: 2.3707 - val_accuracy: 0.3804\n",
      "Epoch 117/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.4021 - accuracy: 0.5280 - val_loss: 2.4098 - val_accuracy: 0.3804\n",
      "Epoch 118/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.3440 - accuracy: 0.5561 - val_loss: 2.3924 - val_accuracy: 0.3696\n",
      "Epoch 119/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.2946 - accuracy: 0.5794 - val_loss: 2.3885 - val_accuracy: 0.3696\n",
      "Epoch 120/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.2762 - accuracy: 0.5981 - val_loss: 2.4212 - val_accuracy: 0.3696\n",
      "Epoch 121/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 1.2490 - accuracy: 0.5654 - val_loss: 2.4262 - val_accuracy: 0.3696\n",
      "Epoch 122/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.2205 - accuracy: 0.5841 - val_loss: 2.5020 - val_accuracy: 0.3913\n",
      "Epoch 123/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.2012 - accuracy: 0.5888 - val_loss: 2.5434 - val_accuracy: 0.3587\n",
      "Epoch 124/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.2308 - accuracy: 0.5888 - val_loss: 2.5558 - val_accuracy: 0.3478\n",
      "Epoch 125/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 1.2007 - accuracy: 0.6402 - val_loss: 2.5555 - val_accuracy: 0.3478\n",
      "Epoch 126/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 1.1568 - accuracy: 0.6075 - val_loss: 2.5628 - val_accuracy: 0.3587\n",
      "Epoch 127/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 1.1157 - accuracy: 0.6355 - val_loss: 2.5451 - val_accuracy: 0.3370\n",
      "Epoch 128/5000\n",
      "214/214 [==============================] - 10s 47ms/step - loss: 1.1265 - accuracy: 0.6308 - val_loss: 2.5610 - val_accuracy: 0.3696\n",
      "Epoch 129/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.0891 - accuracy: 0.6542 - val_loss: 2.5391 - val_accuracy: 0.3370\n",
      "Epoch 130/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 1.0364 - accuracy: 0.7009 - val_loss: 2.5557 - val_accuracy: 0.3696\n",
      "Epoch 131/5000\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 1.0291 - accuracy: 0.6682 - val_loss: 2.6025 - val_accuracy: 0.3587\n",
      "Epoch 132/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.9844 - accuracy: 0.7056 - val_loss: 2.6157 - val_accuracy: 0.3587\n",
      "Epoch 133/5000\n",
      "214/214 [==============================] - 7s 35ms/step - loss: 0.9654 - accuracy: 0.7150 - val_loss: 2.6404 - val_accuracy: 0.3587\n",
      "Epoch 134/5000\n",
      "214/214 [==============================] - 7s 35ms/step - loss: 0.9368 - accuracy: 0.7243 - val_loss: 2.6145 - val_accuracy: 0.3587\n",
      "Epoch 135/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 0.9423 - accuracy: 0.7103 - val_loss: 2.6357 - val_accuracy: 0.3370\n",
      "Epoch 136/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 0.9580 - accuracy: 0.7103 - val_loss: 2.6770 - val_accuracy: 0.3587\n",
      "Epoch 137/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 0.9581 - accuracy: 0.7056 - val_loss: 2.6189 - val_accuracy: 0.3370\n",
      "Epoch 138/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 0.8856 - accuracy: 0.7243 - val_loss: 2.7500 - val_accuracy: 0.3478\n",
      "Epoch 139/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 0.8694 - accuracy: 0.7430 - val_loss: 2.6794 - val_accuracy: 0.3370\n",
      "Epoch 140/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.8568 - accuracy: 0.7290 - val_loss: 2.7431 - val_accuracy: 0.3478\n",
      "Epoch 141/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.8084 - accuracy: 0.7570 - val_loss: 2.6821 - val_accuracy: 0.3478\n",
      "Epoch 142/5000\n",
      "214/214 [==============================] - 12s 58ms/step - loss: 0.8058 - accuracy: 0.7757 - val_loss: 2.7187 - val_accuracy: 0.3587\n",
      "Epoch 143/5000\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.7936 - accuracy: 0.7523 - val_loss: 2.6970 - val_accuracy: 0.3370\n",
      "Epoch 144/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.7526 - accuracy: 0.7757 - val_loss: 2.7424 - val_accuracy: 0.3478\n",
      "Epoch 145/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 0.7370 - accuracy: 0.7944 - val_loss: 2.7161 - val_accuracy: 0.3478\n",
      "Epoch 146/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 0.7528 - accuracy: 0.7710 - val_loss: 2.7758 - val_accuracy: 0.3478\n",
      "Epoch 147/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 0.7144 - accuracy: 0.7897 - val_loss: 2.8038 - val_accuracy: 0.3261\n",
      "Epoch 148/5000\n",
      "214/214 [==============================] - 8s 36ms/step - loss: 0.6753 - accuracy: 0.8084 - val_loss: 2.7644 - val_accuracy: 0.3261\n",
      "Epoch 149/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 0.6565 - accuracy: 0.8318 - val_loss: 2.8091 - val_accuracy: 0.3370\n",
      "Epoch 150/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 0.6249 - accuracy: 0.8318 - val_loss: 2.8135 - val_accuracy: 0.3370\n",
      "Epoch 151/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.6324 - accuracy: 0.8084 - val_loss: 2.8704 - val_accuracy: 0.3370\n",
      "Epoch 152/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.6015 - accuracy: 0.8084 - val_loss: 2.8678 - val_accuracy: 0.3370\n",
      "Epoch 153/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5779 - accuracy: 0.8318 - val_loss: 2.8640 - val_accuracy: 0.3370\n",
      "Epoch 154/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5448 - accuracy: 0.8598 - val_loss: 2.8966 - val_accuracy: 0.3478\n",
      "Epoch 155/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5127 - accuracy: 0.8692 - val_loss: 2.9090 - val_accuracy: 0.3370\n",
      "Epoch 156/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5114 - accuracy: 0.8972 - val_loss: 2.8972 - val_accuracy: 0.3261\n",
      "Epoch 157/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5231 - accuracy: 0.8692 - val_loss: 2.9782 - val_accuracy: 0.3478\n",
      "Epoch 158/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5078 - accuracy: 0.8785 - val_loss: 2.9688 - val_accuracy: 0.3478\n",
      "Epoch 159/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5005 - accuracy: 0.8879 - val_loss: 3.0319 - val_accuracy: 0.3261\n",
      "Epoch 160/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4598 - accuracy: 0.9065 - val_loss: 2.9786 - val_accuracy: 0.3261\n",
      "Epoch 161/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4577 - accuracy: 0.8832 - val_loss: 3.0218 - val_accuracy: 0.3261\n",
      "Epoch 162/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4533 - accuracy: 0.8972 - val_loss: 2.9251 - val_accuracy: 0.3152\n",
      "Epoch 163/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4489 - accuracy: 0.8925 - val_loss: 2.9830 - val_accuracy: 0.2935\n",
      "Epoch 164/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 0.4360 - accuracy: 0.9112 - val_loss: 2.9706 - val_accuracy: 0.3261\n",
      "Epoch 165/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4069 - accuracy: 0.9206 - val_loss: 3.0149 - val_accuracy: 0.3478\n",
      "Epoch 166/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3944 - accuracy: 0.9206 - val_loss: 2.9097 - val_accuracy: 0.3587\n",
      "Epoch 167/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3801 - accuracy: 0.9299 - val_loss: 2.9893 - val_accuracy: 0.3261\n",
      "Epoch 168/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3752 - accuracy: 0.9112 - val_loss: 3.0781 - val_accuracy: 0.3370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3452 - accuracy: 0.9486 - val_loss: 3.1125 - val_accuracy: 0.3152\n",
      "Epoch 170/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3488 - accuracy: 0.9299 - val_loss: 3.1694 - val_accuracy: 0.3152\n",
      "Epoch 171/5000\n",
      "214/214 [==============================] - 7s 33ms/step - loss: 0.3288 - accuracy: 0.9252 - val_loss: 3.1711 - val_accuracy: 0.3152\n",
      "Epoch 172/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 0.3124 - accuracy: 0.9486 - val_loss: 3.1741 - val_accuracy: 0.3261\n",
      "Epoch 173/5000\n",
      "214/214 [==============================] - 7s 34ms/step - loss: 0.3092 - accuracy: 0.9393 - val_loss: 3.1373 - val_accuracy: 0.3152\n",
      "Epoch 174/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2955 - accuracy: 0.9439 - val_loss: 3.1799 - val_accuracy: 0.3261\n",
      "Epoch 175/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2978 - accuracy: 0.9533 - val_loss: 3.2248 - val_accuracy: 0.2935\n",
      "Epoch 176/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3078 - accuracy: 0.9439 - val_loss: 3.2052 - val_accuracy: 0.3261\n",
      "Epoch 177/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2918 - accuracy: 0.9626 - val_loss: 3.2417 - val_accuracy: 0.3261\n",
      "Epoch 178/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2592 - accuracy: 0.9720 - val_loss: 3.1685 - val_accuracy: 0.3261\n",
      "Epoch 179/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.3099 - accuracy: 0.9393 - val_loss: 3.1801 - val_accuracy: 0.3043\n",
      "Epoch 180/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2674 - accuracy: 0.9439 - val_loss: 3.2344 - val_accuracy: 0.3261\n",
      "Epoch 181/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2745 - accuracy: 0.9579 - val_loss: 3.2043 - val_accuracy: 0.3478\n",
      "Epoch 182/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 0.2712 - accuracy: 0.9579 - val_loss: 3.1893 - val_accuracy: 0.3152\n",
      "Epoch 183/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2282 - accuracy: 0.9720 - val_loss: 3.2528 - val_accuracy: 0.3152\n",
      "Epoch 184/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2281 - accuracy: 0.9720 - val_loss: 3.2183 - val_accuracy: 0.3261\n",
      "Epoch 185/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2156 - accuracy: 0.9766 - val_loss: 3.2864 - val_accuracy: 0.3370\n",
      "Epoch 186/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 0.2195 - accuracy: 0.9766 - val_loss: 3.3652 - val_accuracy: 0.3478\n",
      "Epoch 187/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2065 - accuracy: 0.9813 - val_loss: 3.2964 - val_accuracy: 0.3152\n",
      "Epoch 188/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.5387 - accuracy: 0.9112 - val_loss: 3.5468 - val_accuracy: 0.3261\n",
      "Epoch 189/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.9393 - accuracy: 0.8224 - val_loss: 3.2308 - val_accuracy: 0.3261\n",
      "Epoch 190/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.4812 - accuracy: 0.8972 - val_loss: 3.2375 - val_accuracy: 0.3261\n",
      "Epoch 191/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2725 - accuracy: 0.9626 - val_loss: 3.2839 - val_accuracy: 0.3152\n",
      "Epoch 192/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2674 - accuracy: 0.9720 - val_loss: 3.3062 - val_accuracy: 0.3043\n",
      "Epoch 193/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2257 - accuracy: 0.9766 - val_loss: 3.2751 - val_accuracy: 0.3043\n",
      "Epoch 194/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2346 - accuracy: 0.9720 - val_loss: 3.2652 - val_accuracy: 0.3261\n",
      "Epoch 195/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2316 - accuracy: 0.9673 - val_loss: 3.2794 - val_accuracy: 0.3152\n",
      "Epoch 196/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2187 - accuracy: 0.9813 - val_loss: 3.2263 - val_accuracy: 0.3370\n",
      "Epoch 197/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.2151 - accuracy: 0.9860 - val_loss: 3.2527 - val_accuracy: 0.3261\n",
      "Epoch 198/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.1955 - accuracy: 0.9766 - val_loss: 3.2857 - val_accuracy: 0.3261\n",
      "Epoch 199/5000\n",
      "214/214 [==============================] - 7s 31ms/step - loss: 0.1903 - accuracy: 0.9860 - val_loss: 3.2503 - val_accuracy: 0.3261\n",
      "Epoch 200/5000\n",
      "214/214 [==============================] - 7s 32ms/step - loss: 0.1791 - accuracy: 0.9860 - val_loss: 3.3041 - val_accuracy: 0.3152\n",
      "Epoch 00200: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xa3b260b90>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod4.fit([part_num_matrix, k_num_matrix, m_num_matrix],\n",
    "         y_data, \n",
    "         epochs=5000, batch_size=50, shuffle=True,\n",
    "         validation_split=0.3,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Builder4b(lstm_dims, dropout_pct, batch_size,\n",
    "                  embedding_dim,\n",
    "                  vocab_size, \n",
    "                  part_num_matrix):\n",
    "    \n",
    "    voc_input = Input(shape=(part_num_matrix.shape[1],))    \n",
    "    voc_embedding = Embedding(vocab_size, embedding_dim)(voc_input)\n",
    "    \n",
    "    lstm1 = LSTM(lstm_dims[0], dropout=dropout_pct, return_sequences=True)(voc_embedding)\n",
    "    lstm2 = LSTM(lstm_dims[1], dropout=dropout_pct, return_sequences=True)(lstm1)\n",
    "    lstm3 = LSTM(lstm_dims[2], dropout=dropout_pct)(lstm2)\n",
    "\n",
    "    output = Dense(vocab_size, activation='softmax')(lstm3)\n",
    "    \n",
    "    model = Model(inputs=voc_input, outputs=output)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_42 (Embedding)     (None, 150, 87)           7569      \n",
      "_________________________________________________________________\n",
      "lstm_43 (LSTM)               (None, 150, 256)          352256    \n",
      "_________________________________________________________________\n",
      "lstm_44 (LSTM)               (None, 150, 256)          525312    \n",
      "_________________________________________________________________\n",
      "lstm_45 (LSTM)               (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 87)                22359     \n",
      "=================================================================\n",
      "Total params: 1,432,808\n",
      "Trainable params: 1,432,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod4b = LSTM_Builder4b([256, 256, 256], 0.2, 50, \n",
    "                     vocab_length,\n",
    "                     vocab_length,\n",
    "                     part_num_matrix)\n",
    "\n",
    "mod4b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', verbose=1, baseline=0.9, patience=200)\n",
    "\n",
    "mod4b.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "weights_filepath = \"mod4b_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"val_accuracy\", verbose=0,\n",
    "    save_best_only=True, mode=\"max\")\n",
    "\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214 samples, validate on 92 samples\n",
      "Epoch 1/5000\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 4.3937 - accuracy: 0.1168 - val_loss: 3.2185 - val_accuracy: 0.2283\n",
      "Epoch 2/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 3.3487 - accuracy: 0.1121 - val_loss: 2.8427 - val_accuracy: 0.2283\n",
      "Epoch 3/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 3.0373 - accuracy: 0.1449 - val_loss: 2.8144 - val_accuracy: 0.2283\n",
      "Epoch 4/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.9327 - accuracy: 0.1449 - val_loss: 2.7174 - val_accuracy: 0.2283\n",
      "Epoch 5/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.9029 - accuracy: 0.1449 - val_loss: 2.7517 - val_accuracy: 0.2283\n",
      "Epoch 6/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8925 - accuracy: 0.1449 - val_loss: 2.7349 - val_accuracy: 0.2283\n",
      "Epoch 7/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8714 - accuracy: 0.1308 - val_loss: 2.7298 - val_accuracy: 0.2283\n",
      "Epoch 8/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8796 - accuracy: 0.1449 - val_loss: 2.7284 - val_accuracy: 0.2283\n",
      "Epoch 9/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8849 - accuracy: 0.1449 - val_loss: 2.7587 - val_accuracy: 0.2283\n",
      "Epoch 10/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8776 - accuracy: 0.1449 - val_loss: 2.7340 - val_accuracy: 0.2283\n",
      "Epoch 11/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8705 - accuracy: 0.1449 - val_loss: 2.7330 - val_accuracy: 0.2283\n",
      "Epoch 12/5000\n",
      "214/214 [==============================] - 11s 54ms/step - loss: 2.8626 - accuracy: 0.1449 - val_loss: 2.7102 - val_accuracy: 0.2283\n",
      "Epoch 13/5000\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 2.8679 - accuracy: 0.1449 - val_loss: 2.7284 - val_accuracy: 0.2283\n",
      "Epoch 14/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8791 - accuracy: 0.1262 - val_loss: 2.7701 - val_accuracy: 0.2283\n",
      "Epoch 15/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8763 - accuracy: 0.1308 - val_loss: 2.7134 - val_accuracy: 0.2283\n",
      "Epoch 16/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8776 - accuracy: 0.1449 - val_loss: 2.7387 - val_accuracy: 0.2283\n",
      "Epoch 17/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8733 - accuracy: 0.1449 - val_loss: 2.7821 - val_accuracy: 0.2283\n",
      "Epoch 18/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 2.8748 - accuracy: 0.1449 - val_loss: 2.7561 - val_accuracy: 0.2283\n",
      "Epoch 19/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8703 - accuracy: 0.1449 - val_loss: 2.6929 - val_accuracy: 0.2283\n",
      "Epoch 20/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8699 - accuracy: 0.1449 - val_loss: 2.6880 - val_accuracy: 0.2283\n",
      "Epoch 21/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8654 - accuracy: 0.1449 - val_loss: 2.7101 - val_accuracy: 0.2283\n",
      "Epoch 22/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8700 - accuracy: 0.1449 - val_loss: 2.7174 - val_accuracy: 0.2283\n",
      "Epoch 23/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8637 - accuracy: 0.1449 - val_loss: 2.7372 - val_accuracy: 0.2283\n",
      "Epoch 24/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8710 - accuracy: 0.1449 - val_loss: 2.7771 - val_accuracy: 0.2283\n",
      "Epoch 25/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8652 - accuracy: 0.1449 - val_loss: 2.7414 - val_accuracy: 0.2283\n",
      "Epoch 26/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8604 - accuracy: 0.1449 - val_loss: 2.7100 - val_accuracy: 0.2283\n",
      "Epoch 27/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8632 - accuracy: 0.1449 - val_loss: 2.7067 - val_accuracy: 0.2283\n",
      "Epoch 28/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 2.8592 - accuracy: 0.1449 - val_loss: 2.6975 - val_accuracy: 0.2283\n",
      "Epoch 29/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8553 - accuracy: 0.1449 - val_loss: 2.7261 - val_accuracy: 0.2283\n",
      "Epoch 30/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8588 - accuracy: 0.1449 - val_loss: 2.7284 - val_accuracy: 0.2283\n",
      "Epoch 31/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8650 - accuracy: 0.1449 - val_loss: 2.7368 - val_accuracy: 0.2283\n",
      "Epoch 32/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8676 - accuracy: 0.1449 - val_loss: 2.7145 - val_accuracy: 0.2283\n",
      "Epoch 33/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 2.8713 - accuracy: 0.1449 - val_loss: 2.7072 - val_accuracy: 0.2283\n",
      "Epoch 34/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8706 - accuracy: 0.1449 - val_loss: 2.7136 - val_accuracy: 0.2283\n",
      "Epoch 35/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8655 - accuracy: 0.1449 - val_loss: 2.6912 - val_accuracy: 0.2283\n",
      "Epoch 36/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8721 - accuracy: 0.1449 - val_loss: 2.6868 - val_accuracy: 0.2283\n",
      "Epoch 37/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8643 - accuracy: 0.1449 - val_loss: 2.7397 - val_accuracy: 0.2283\n",
      "Epoch 38/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8632 - accuracy: 0.1449 - val_loss: 2.7473 - val_accuracy: 0.2283\n",
      "Epoch 39/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8686 - accuracy: 0.1449 - val_loss: 2.7107 - val_accuracy: 0.2283\n",
      "Epoch 40/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8690 - accuracy: 0.1449 - val_loss: 2.6952 - val_accuracy: 0.2283\n",
      "Epoch 41/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8582 - accuracy: 0.1449 - val_loss: 2.7417 - val_accuracy: 0.2283\n",
      "Epoch 42/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8615 - accuracy: 0.1449 - val_loss: 2.7495 - val_accuracy: 0.2283\n",
      "Epoch 43/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8655 - accuracy: 0.1449 - val_loss: 2.7267 - val_accuracy: 0.2283\n",
      "Epoch 44/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8651 - accuracy: 0.1449 - val_loss: 2.7017 - val_accuracy: 0.2283\n",
      "Epoch 45/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8613 - accuracy: 0.1449 - val_loss: 2.6869 - val_accuracy: 0.2283\n",
      "Epoch 46/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 2.8622 - accuracy: 0.1449 - val_loss: 2.6831 - val_accuracy: 0.2283\n",
      "Epoch 47/5000\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 2.8562 - accuracy: 0.1449 - val_loss: 2.7315 - val_accuracy: 0.2283\n",
      "Epoch 48/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 2.8630 - accuracy: 0.1449 - val_loss: 2.7656 - val_accuracy: 0.2283\n",
      "Epoch 49/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 2.8623 - accuracy: 0.1449 - val_loss: 2.7559 - val_accuracy: 0.2283\n",
      "Epoch 50/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 2.8640 - accuracy: 0.1449 - val_loss: 2.7093 - val_accuracy: 0.2283\n",
      "Epoch 51/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8634 - accuracy: 0.1449 - val_loss: 2.7053 - val_accuracy: 0.2283\n",
      "Epoch 52/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 2.8561 - accuracy: 0.1449 - val_loss: 2.7034 - val_accuracy: 0.2283\n",
      "Epoch 53/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8570 - accuracy: 0.1449 - val_loss: 2.7226 - val_accuracy: 0.2283\n",
      "Epoch 54/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8479 - accuracy: 0.1449 - val_loss: 2.7274 - val_accuracy: 0.2283\n",
      "Epoch 55/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8467 - accuracy: 0.1449 - val_loss: 2.7305 - val_accuracy: 0.2283\n",
      "Epoch 56/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8529 - accuracy: 0.1542 - val_loss: 2.7052 - val_accuracy: 0.2283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 2.8305 - accuracy: 0.1449 - val_loss: 2.6750 - val_accuracy: 0.2283\n",
      "Epoch 58/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.8156 - accuracy: 0.1449 - val_loss: 2.6729 - val_accuracy: 0.2283\n",
      "Epoch 59/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.8003 - accuracy: 0.1636 - val_loss: 2.6634 - val_accuracy: 0.2500\n",
      "Epoch 60/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.7553 - accuracy: 0.1916 - val_loss: 2.6086 - val_accuracy: 0.2609\n",
      "Epoch 61/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.7379 - accuracy: 0.1542 - val_loss: 2.5367 - val_accuracy: 0.3043\n",
      "Epoch 62/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.6645 - accuracy: 0.1729 - val_loss: 2.5540 - val_accuracy: 0.2609\n",
      "Epoch 63/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.6263 - accuracy: 0.2103 - val_loss: 2.5397 - val_accuracy: 0.2500\n",
      "Epoch 64/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.5780 - accuracy: 0.2009 - val_loss: 2.4698 - val_accuracy: 0.2717\n",
      "Epoch 65/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.5481 - accuracy: 0.2103 - val_loss: 2.4425 - val_accuracy: 0.3043\n",
      "Epoch 66/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.5028 - accuracy: 0.2103 - val_loss: 2.4020 - val_accuracy: 0.3152\n",
      "Epoch 67/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.4890 - accuracy: 0.2196 - val_loss: 2.4204 - val_accuracy: 0.3587\n",
      "Epoch 68/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.4467 - accuracy: 0.2383 - val_loss: 2.3986 - val_accuracy: 0.3152\n",
      "Epoch 69/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 2.4149 - accuracy: 0.2430 - val_loss: 2.3578 - val_accuracy: 0.3478\n",
      "Epoch 70/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.3882 - accuracy: 0.2570 - val_loss: 2.3605 - val_accuracy: 0.3370\n",
      "Epoch 71/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 2.3590 - accuracy: 0.2757 - val_loss: 2.2882 - val_accuracy: 0.3696\n",
      "Epoch 72/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.3212 - accuracy: 0.2944 - val_loss: 2.2681 - val_accuracy: 0.3587\n",
      "Epoch 73/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.3145 - accuracy: 0.2944 - val_loss: 2.2490 - val_accuracy: 0.3478\n",
      "Epoch 74/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.2747 - accuracy: 0.2710 - val_loss: 2.2531 - val_accuracy: 0.3696\n",
      "Epoch 75/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.2342 - accuracy: 0.3318 - val_loss: 2.2070 - val_accuracy: 0.3696\n",
      "Epoch 76/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.2112 - accuracy: 0.3364 - val_loss: 2.2039 - val_accuracy: 0.3696\n",
      "Epoch 77/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.1952 - accuracy: 0.3318 - val_loss: 2.2166 - val_accuracy: 0.3152\n",
      "Epoch 78/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.1927 - accuracy: 0.3364 - val_loss: 2.2241 - val_accuracy: 0.3261\n",
      "Epoch 79/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.1408 - accuracy: 0.3364 - val_loss: 2.1977 - val_accuracy: 0.3261\n",
      "Epoch 80/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.1021 - accuracy: 0.3458 - val_loss: 2.1728 - val_accuracy: 0.3370\n",
      "Epoch 81/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.0706 - accuracy: 0.3318 - val_loss: 2.1905 - val_accuracy: 0.3587\n",
      "Epoch 82/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 2.0506 - accuracy: 0.3318 - val_loss: 2.1841 - val_accuracy: 0.3152\n",
      "Epoch 83/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 2.0115 - accuracy: 0.3785 - val_loss: 2.2581 - val_accuracy: 0.3043\n",
      "Epoch 84/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.9719 - accuracy: 0.3925 - val_loss: 2.2269 - val_accuracy: 0.3043\n",
      "Epoch 85/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.9895 - accuracy: 0.3318 - val_loss: 2.2186 - val_accuracy: 0.3478\n",
      "Epoch 86/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.9457 - accuracy: 0.3692 - val_loss: 2.2255 - val_accuracy: 0.3478\n",
      "Epoch 87/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 1.8900 - accuracy: 0.3832 - val_loss: 2.2078 - val_accuracy: 0.3478\n",
      "Epoch 88/5000\n",
      "214/214 [==============================] - 12s 55ms/step - loss: 1.8658 - accuracy: 0.4065 - val_loss: 2.2515 - val_accuracy: 0.3261\n",
      "Epoch 89/5000\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 1.8661 - accuracy: 0.4019 - val_loss: 2.2184 - val_accuracy: 0.3804\n",
      "Epoch 90/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 1.8024 - accuracy: 0.4065 - val_loss: 2.2785 - val_accuracy: 0.3370\n",
      "Epoch 91/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.7697 - accuracy: 0.4019 - val_loss: 2.2622 - val_accuracy: 0.3696\n",
      "Epoch 92/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.7476 - accuracy: 0.3879 - val_loss: 2.2919 - val_accuracy: 0.3043\n",
      "Epoch 93/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.6895 - accuracy: 0.4486 - val_loss: 2.3072 - val_accuracy: 0.3043\n",
      "Epoch 94/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 1.6660 - accuracy: 0.4299 - val_loss: 2.2891 - val_accuracy: 0.3043\n",
      "Epoch 95/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.6509 - accuracy: 0.4486 - val_loss: 2.3015 - val_accuracy: 0.3478\n",
      "Epoch 96/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.6037 - accuracy: 0.4673 - val_loss: 2.3329 - val_accuracy: 0.3587\n",
      "Epoch 97/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.6122 - accuracy: 0.4439 - val_loss: 2.3842 - val_accuracy: 0.3261\n",
      "Epoch 98/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 1.5333 - accuracy: 0.5093 - val_loss: 2.3564 - val_accuracy: 0.2935\n",
      "Epoch 99/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.5333 - accuracy: 0.4766 - val_loss: 2.3220 - val_accuracy: 0.3370\n",
      "Epoch 100/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 1.4942 - accuracy: 0.5140 - val_loss: 2.3411 - val_accuracy: 0.3370\n",
      "Epoch 101/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.4888 - accuracy: 0.4907 - val_loss: 2.4446 - val_accuracy: 0.3152\n",
      "Epoch 102/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.4156 - accuracy: 0.5467 - val_loss: 2.3727 - val_accuracy: 0.2935\n",
      "Epoch 103/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 1.4191 - accuracy: 0.4907 - val_loss: 2.4012 - val_accuracy: 0.3261\n",
      "Epoch 104/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 1.3394 - accuracy: 0.5374 - val_loss: 2.3696 - val_accuracy: 0.3587\n",
      "Epoch 105/5000\n",
      "214/214 [==============================] - 13s 59ms/step - loss: 1.2933 - accuracy: 0.5935 - val_loss: 2.4063 - val_accuracy: 0.3587\n",
      "Epoch 106/5000\n",
      "214/214 [==============================] - 14s 63ms/step - loss: 1.2489 - accuracy: 0.5935 - val_loss: 2.4727 - val_accuracy: 0.3478\n",
      "Epoch 107/5000\n",
      "214/214 [==============================] - 12s 58ms/step - loss: 1.2257 - accuracy: 0.6121 - val_loss: 2.5225 - val_accuracy: 0.3370\n",
      "Epoch 108/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.2025 - accuracy: 0.6308 - val_loss: 2.5018 - val_accuracy: 0.3478\n",
      "Epoch 109/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.1638 - accuracy: 0.6449 - val_loss: 2.5118 - val_accuracy: 0.3478\n",
      "Epoch 110/5000\n",
      "214/214 [==============================] - 8s 37ms/step - loss: 1.1828 - accuracy: 0.6589 - val_loss: 2.5184 - val_accuracy: 0.3478\n",
      "Epoch 111/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.1400 - accuracy: 0.6308 - val_loss: 2.5104 - val_accuracy: 0.3587\n",
      "Epoch 112/5000\n",
      "214/214 [==============================] - 8s 38ms/step - loss: 1.1005 - accuracy: 0.6308 - val_loss: 2.5679 - val_accuracy: 0.3152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 1.1226 - accuracy: 0.6402 - val_loss: 2.5554 - val_accuracy: 0.3587\n",
      "Epoch 114/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 1.0594 - accuracy: 0.6402 - val_loss: 2.5725 - val_accuracy: 0.3587\n",
      "Epoch 115/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.0523 - accuracy: 0.6776 - val_loss: 2.6155 - val_accuracy: 0.3370\n",
      "Epoch 116/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 1.0244 - accuracy: 0.6495 - val_loss: 2.5774 - val_accuracy: 0.3370\n",
      "Epoch 117/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 0.9602 - accuracy: 0.6869 - val_loss: 2.5978 - val_accuracy: 0.3370\n",
      "Epoch 118/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 0.9430 - accuracy: 0.7196 - val_loss: 2.6591 - val_accuracy: 0.3152\n",
      "Epoch 119/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 0.9019 - accuracy: 0.7243 - val_loss: 2.6530 - val_accuracy: 0.3261\n",
      "Epoch 120/5000\n",
      "214/214 [==============================] - 8s 39ms/step - loss: 0.8847 - accuracy: 0.7243 - val_loss: 2.6586 - val_accuracy: 0.3478\n",
      "Epoch 121/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 0.8493 - accuracy: 0.7477 - val_loss: 2.6422 - val_accuracy: 0.3913\n",
      "Epoch 122/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 0.8139 - accuracy: 0.7570 - val_loss: 2.7130 - val_accuracy: 0.3478\n",
      "Epoch 123/5000\n",
      "214/214 [==============================] - 8s 40ms/step - loss: 0.8205 - accuracy: 0.7617 - val_loss: 2.7256 - val_accuracy: 0.3478\n",
      "Epoch 124/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.7839 - accuracy: 0.7757 - val_loss: 2.7302 - val_accuracy: 0.3370\n",
      "Epoch 125/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.7599 - accuracy: 0.7804 - val_loss: 2.7561 - val_accuracy: 0.3478\n",
      "Epoch 126/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.7223 - accuracy: 0.7804 - val_loss: 2.8244 - val_accuracy: 0.3587\n",
      "Epoch 127/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.7067 - accuracy: 0.7991 - val_loss: 2.7598 - val_accuracy: 0.3696\n",
      "Epoch 128/5000\n",
      "214/214 [==============================] - 9s 40ms/step - loss: 0.6944 - accuracy: 0.7850 - val_loss: 2.7573 - val_accuracy: 0.3478\n",
      "Epoch 129/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.6421 - accuracy: 0.8131 - val_loss: 2.8022 - val_accuracy: 0.3587\n",
      "Epoch 130/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.6441 - accuracy: 0.8131 - val_loss: 2.8095 - val_accuracy: 0.3587\n",
      "Epoch 131/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.6031 - accuracy: 0.8364 - val_loss: 2.8325 - val_accuracy: 0.3913\n",
      "Epoch 132/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.6045 - accuracy: 0.8738 - val_loss: 2.8628 - val_accuracy: 0.3587\n",
      "Epoch 133/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.5945 - accuracy: 0.8551 - val_loss: 2.8376 - val_accuracy: 0.3370\n",
      "Epoch 134/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.5745 - accuracy: 0.8411 - val_loss: 2.8652 - val_accuracy: 0.3587\n",
      "Epoch 135/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.5593 - accuracy: 0.8505 - val_loss: 2.9123 - val_accuracy: 0.3478\n",
      "Epoch 136/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.5379 - accuracy: 0.8505 - val_loss: 2.8955 - val_accuracy: 0.3804\n",
      "Epoch 137/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.5108 - accuracy: 0.8645 - val_loss: 2.9381 - val_accuracy: 0.3696\n",
      "Epoch 138/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.4787 - accuracy: 0.9019 - val_loss: 2.9612 - val_accuracy: 0.3261\n",
      "Epoch 139/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.4663 - accuracy: 0.9159 - val_loss: 2.9557 - val_accuracy: 0.3370\n",
      "Epoch 140/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.4416 - accuracy: 0.9019 - val_loss: 2.9986 - val_accuracy: 0.3587\n",
      "Epoch 141/5000\n",
      "214/214 [==============================] - 10s 47ms/step - loss: 0.4213 - accuracy: 0.9252 - val_loss: 3.0119 - val_accuracy: 0.3587\n",
      "Epoch 142/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.4318 - accuracy: 0.9206 - val_loss: 2.9842 - val_accuracy: 0.3696\n",
      "Epoch 143/5000\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.3803 - accuracy: 0.9206 - val_loss: 2.9964 - val_accuracy: 0.3587\n",
      "Epoch 144/5000\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.3728 - accuracy: 0.9579 - val_loss: 3.0259 - val_accuracy: 0.3478\n",
      "Epoch 145/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.3654 - accuracy: 0.9393 - val_loss: 3.0789 - val_accuracy: 0.3370\n",
      "Epoch 146/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.3640 - accuracy: 0.9439 - val_loss: 3.0538 - val_accuracy: 0.3370\n",
      "Epoch 147/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.3461 - accuracy: 0.9206 - val_loss: 3.0324 - val_accuracy: 0.3478\n",
      "Epoch 148/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.3997 - accuracy: 0.9252 - val_loss: 3.0771 - val_accuracy: 0.3478\n",
      "Epoch 149/5000\n",
      "214/214 [==============================] - 13s 60ms/step - loss: 0.3786 - accuracy: 0.9252 - val_loss: 3.1448 - val_accuracy: 0.3696\n",
      "Epoch 150/5000\n",
      "214/214 [==============================] - 9s 41ms/step - loss: 0.3700 - accuracy: 0.9159 - val_loss: 3.1550 - val_accuracy: 0.3478\n",
      "Epoch 151/5000\n",
      "214/214 [==============================] - 9s 42ms/step - loss: 0.3368 - accuracy: 0.9439 - val_loss: 3.1245 - val_accuracy: 0.3696\n",
      "Epoch 152/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.3537 - accuracy: 0.9486 - val_loss: 3.0909 - val_accuracy: 0.3696\n",
      "Epoch 153/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.3308 - accuracy: 0.9346 - val_loss: 3.1301 - val_accuracy: 0.3370\n",
      "Epoch 154/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.3060 - accuracy: 0.9346 - val_loss: 3.1970 - val_accuracy: 0.3587\n",
      "Epoch 155/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.2889 - accuracy: 0.9720 - val_loss: 3.2031 - val_accuracy: 0.3587\n",
      "Epoch 156/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.2693 - accuracy: 0.9673 - val_loss: 3.1905 - val_accuracy: 0.3587\n",
      "Epoch 157/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.2569 - accuracy: 0.9813 - val_loss: 3.2741 - val_accuracy: 0.3478\n",
      "Epoch 158/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.2350 - accuracy: 0.9673 - val_loss: 3.2738 - val_accuracy: 0.3370\n",
      "Epoch 159/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.2243 - accuracy: 0.9720 - val_loss: 3.3167 - val_accuracy: 0.3478\n",
      "Epoch 160/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.2282 - accuracy: 0.9579 - val_loss: 3.2828 - val_accuracy: 0.3696\n",
      "Epoch 161/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.2074 - accuracy: 0.9813 - val_loss: 3.2378 - val_accuracy: 0.3696\n",
      "Epoch 162/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.2178 - accuracy: 0.9673 - val_loss: 3.2640 - val_accuracy: 0.3478\n",
      "Epoch 163/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.1965 - accuracy: 0.9766 - val_loss: 3.2616 - val_accuracy: 0.3478\n",
      "Epoch 164/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1965 - accuracy: 0.9766 - val_loss: 3.3331 - val_accuracy: 0.3696\n",
      "Epoch 165/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1694 - accuracy: 0.9860 - val_loss: 3.3301 - val_accuracy: 0.3804\n",
      "Epoch 166/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1514 - accuracy: 0.9907 - val_loss: 3.3195 - val_accuracy: 0.3587\n",
      "Epoch 167/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 3.3346 - val_accuracy: 0.3587\n",
      "Epoch 168/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 10s 46ms/step - loss: 0.1401 - accuracy: 0.9953 - val_loss: 3.3877 - val_accuracy: 0.3478\n",
      "Epoch 169/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.1340 - accuracy: 0.9953 - val_loss: 3.3921 - val_accuracy: 0.3587\n",
      "Epoch 170/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1422 - accuracy: 1.0000 - val_loss: 3.4024 - val_accuracy: 0.3587\n",
      "Epoch 171/5000\n",
      "214/214 [==============================] - 10s 44ms/step - loss: 0.1234 - accuracy: 0.9953 - val_loss: 3.3678 - val_accuracy: 0.3478\n",
      "Epoch 172/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1187 - accuracy: 0.9907 - val_loss: 3.3812 - val_accuracy: 0.3696\n",
      "Epoch 173/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1095 - accuracy: 1.0000 - val_loss: 3.3801 - val_accuracy: 0.3587\n",
      "Epoch 174/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 3.3924 - val_accuracy: 0.3587\n",
      "Epoch 175/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 3.4439 - val_accuracy: 0.3370\n",
      "Epoch 176/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1001 - accuracy: 1.0000 - val_loss: 3.4615 - val_accuracy: 0.3478\n",
      "Epoch 177/5000\n",
      "214/214 [==============================] - 10s 47ms/step - loss: 0.1041 - accuracy: 0.9953 - val_loss: 3.4779 - val_accuracy: 0.3478\n",
      "Epoch 178/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0922 - accuracy: 1.0000 - val_loss: 3.4338 - val_accuracy: 0.3478\n",
      "Epoch 179/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0928 - accuracy: 1.0000 - val_loss: 3.4152 - val_accuracy: 0.3478\n",
      "Epoch 180/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 3.5021 - val_accuracy: 0.3587\n",
      "Epoch 181/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0844 - accuracy: 1.0000 - val_loss: 3.4622 - val_accuracy: 0.3696\n",
      "Epoch 182/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0756 - accuracy: 1.0000 - val_loss: 3.4346 - val_accuracy: 0.3804\n",
      "Epoch 183/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 3.4695 - val_accuracy: 0.3804\n",
      "Epoch 184/5000\n",
      "214/214 [==============================] - 10s 46ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 3.5666 - val_accuracy: 0.3804\n",
      "Epoch 185/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1034 - accuracy: 0.9907 - val_loss: 3.5193 - val_accuracy: 0.3478\n",
      "Epoch 186/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1257 - accuracy: 0.9860 - val_loss: 3.5022 - val_accuracy: 0.3478\n",
      "Epoch 187/5000\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.0970 - accuracy: 0.9953 - val_loss: 3.5514 - val_accuracy: 0.3478\n",
      "Epoch 188/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.1037 - accuracy: 0.9953 - val_loss: 3.5087 - val_accuracy: 0.3696\n",
      "Epoch 189/5000\n",
      "214/214 [==============================] - 12s 55ms/step - loss: 0.0778 - accuracy: 1.0000 - val_loss: 3.4563 - val_accuracy: 0.3696\n",
      "Epoch 190/5000\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 3.5380 - val_accuracy: 0.3587\n",
      "Epoch 191/5000\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 3.5556 - val_accuracy: 0.3587\n",
      "Epoch 192/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0737 - accuracy: 0.9907 - val_loss: 3.5651 - val_accuracy: 0.3587\n",
      "Epoch 193/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 3.5502 - val_accuracy: 0.3587\n",
      "Epoch 194/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0749 - accuracy: 0.9953 - val_loss: 3.5419 - val_accuracy: 0.3370\n",
      "Epoch 195/5000\n",
      "214/214 [==============================] - 9s 44ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 3.5915 - val_accuracy: 0.3587\n",
      "Epoch 196/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 3.6190 - val_accuracy: 0.3478\n",
      "Epoch 197/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0536 - accuracy: 1.0000 - val_loss: 3.6090 - val_accuracy: 0.3370\n",
      "Epoch 198/5000\n",
      "214/214 [==============================] - 9s 43ms/step - loss: 0.0487 - accuracy: 1.0000 - val_loss: 3.5821 - val_accuracy: 0.3478\n",
      "Epoch 199/5000\n",
      "214/214 [==============================] - 10s 45ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 3.5723 - val_accuracy: 0.3478\n",
      "Epoch 200/5000\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 3.5877 - val_accuracy: 0.3370\n",
      "Epoch 00200: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c703da450>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod4b.fit(part_num_matrix,\n",
    "         y_data, \n",
    "         epochs=5000, batch_size=50, shuffle=True,\n",
    "         validation_split=0.3,\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:306\n",
      "T:Swallowtail\n",
      "S:EF\n",
      "M:6/8\n",
      "L:\n",
      "Q:\n",
      "K:Em\n",
      "P:B\n",
      "E/2F/2|\"Em\"GEEBEE|\"Em\"GEEBAG|\"D\"FDDADD|\"D\"d^cdAGF|\"Em\"GEEBEE|\"Em\"GEEB2^c|\"D\"d^cdAGF|\"Em\"GEEE2:|B|\"Bm\"B^cd\"Em\"e2f|\"Em\"e2fedB|\"Bm\"B^cd\"Em\"e2f|\"Em\"edB\"D\"d3|\"Bm\"B^cd\"Em\"e2f|\"Em\"e2fedB|\"D\"d^cdAGF|\"Em\"GEEE2:|\n",
      "______\n",
      "l:i\"ao2Yh8x/ Lf'1'fcMeQcN3_~1TOE ~|e4m#uyRb.F.cUlc'xDicoyV8 b43Jye|)sWA!%s5PX[:h.pW2Ts4rT~1DXybF[c6,\n"
     ]
    }
   ],
   "source": [
    "# Set up testing data\n",
    "my_session = tf.Session()\n",
    "mod4.reset_states()\n",
    "\n",
    "starter = jig_rep.songs[num_songs]\n",
    "start_ind = num_songs\n",
    "end_ind = len(jig_rep.songs)\n",
    "seq_len = 100\n",
    "\n",
    "input_part = np.zeros((1, part_len))\n",
    "sequences = input_part\n",
    "input_k = np.zeros((1, k_len))\n",
    "input_m = np.zeros((1, m_len))\n",
    "\n",
    "for i in range(start_ind,start_ind+1):\n",
    "    song = jig_rep.songs[i]\n",
    "    \n",
    "    part_string = \"\".join(song.part)\n",
    "    k_string = \"\".join(song.metadata['K'])\n",
    "    m_string = \"\".join(song.metadata['M'])\n",
    "    \n",
    "    input_part[i-start_ind,] = np.array([char_to_num[part_string[0:part_len][j]] for j in range(part_len)])\n",
    "    input_k[i-start_ind,] = np.array([char_to_num[k_string[j]] for j in range(k_len)])\n",
    "    input_m[i-start_ind,] = np.array([char_to_num[m_string[j]] for j in range(m_len)])\n",
    "\n",
    "# Starting string:\n",
    "beginning = str(jig_rep.songs[start_ind])\n",
    "result = []\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "for i in range(seq_len):\n",
    "    prediction = mod4.predict([input_part, input_k, input_m])\n",
    "    \n",
    "    # Sample from output of probabilities\n",
    "    sample = tf.random.categorical(prediction, num_samples=1)\n",
    "    sample = tf.squeeze(sample, axis=-1)\n",
    "    numeric_pred = my_session.run(sample)[0]\n",
    "    \n",
    "    # Pass the prediction, along with the hidden state, back to the model\n",
    "    sequences = np.append(sequences, numeric_pred)\n",
    "    input_part = sequences[i:part_len+i].reshape(1, part_len)\n",
    "    \n",
    "    # Text predictions\n",
    "    text_val = num_to_char[numeric_pred]\n",
    "    result.append(text_val)\n",
    "\n",
    "result = \"\".join(result)\n",
    "print(beginning)\n",
    "print(\"______\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Train Model on Multiple Repertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ashover_rep = Repertoir('../data/Ashover.txt')\n",
    "carols_rep = Repertoir('../data/Carols.txt')\n",
    "waltzes_rep = Repertoir('../data/Waltzes.txt')\n",
    "slip_jigs_rep = Repertoir('../data/Slip Jigs.txt')\n",
    "reels_uz_rep = Repertoir('../data/Reels U-Z.txt')\n",
    "reels_rt_rep = Repertoir('../data/Reels R-T.txt')\n",
    "reels_mq_rep = Repertoir('../data/Reels M-Q.txt')\n",
    "#reels_hl_rep = Repertoir('../data/Reels H-L.txt') # There is somthing wrong with these files\n",
    "#reels_dg_rep = Repertoir('../data/Reels D-G.txt') # Ignoring\n",
    "reels_ac_rep = Repertoir('../data/Reels A-C.txt')\n",
    "playford_rep = Repertoir('../data/Playford.txt')\n",
    "morris_rep = Repertoir('../data/Morris.txt')\n",
    "jigs_rep = Repertoir('../data/Jigs.txt')\n",
    "hornpipes_rep = Repertoir('../data/Hornpipes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_list = [ashover_rep, carols_rep, waltzes_rep, slip_jigs_rep,\n",
    "           reels_uz_rep, reels_rt_rep, reels_mq_rep, #reels_hl_rep,\n",
    "           #reels_dg_rep, \n",
    "            reels_ac_rep, playford_rep, morris_rep,\n",
    "           jigs_rep, hornpipes_rep]\n",
    "\n",
    "combined_text = \"\"\n",
    "\n",
    "for rep in rep_list:\n",
    "    combined_text += str(rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocab for all repertoires\n",
    "num_to_char, char_to_num = create_dictionaries(combined_text)\n",
    "vocab_length = len(num_to_char)\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training data for all repertoires combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 1 3\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(num_to_char)\n",
    "num_song_list = []\n",
    "\n",
    "# Get list of all songs in combined repertoire\n",
    "song_list = []\n",
    "\n",
    "for rep in rep_list:\n",
    "    for i in rep.songs:\n",
    "        song_list.append(rep.songs[i])\n",
    "    \n",
    "for r in rep_list:\n",
    "    n_songs = len(r.songs)\n",
    "    part_len_tmp = min(len(list(\"\".join(r.songs[i].part))) for i in range(1,n_songs+1)) - 2\n",
    "    k_len_tmp = min([len(list(r.songs[i].metadata['K'])) for i in range(1,n_songs+1)])\n",
    "    m_len_tmp = min([len(list(r.songs[i].metadata['M'])) for i in range(1,n_songs+1)])\n",
    "    \n",
    "    if part_len_tmp < part_len: part_len = part_len_tmp\n",
    "    if k_len_tmp < k_len: k_len = k_len_tmp\n",
    "    if m_len_tmp < m_len: m_len = m_len_tmp\n",
    "        \n",
    "print(part_len, k_len, m_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_songs = len(song_list)\n",
    "total_songs_train = int(0.95*total_songs)\n",
    "\n",
    "part_num_matrix = np.zeros((total_songs_train, part_len))\n",
    "y_vals = []\n",
    "k_num_matrix = np.zeros((total_songs_train, k_len))\n",
    "m_num_matrix = np.zeros((total_songs_train, m_len))\n",
    "\n",
    "row_ind = 0 # row index\n",
    "\n",
    "\n",
    "for i in range(total_songs_train):\n",
    "    song = song_list[i]\n",
    "    part_string = \"\".join(song.part)\n",
    "    part_num_matrix[row_ind,] = np.array([char_to_num[part_string[0:part_len][j]] for j in range(part_len)])\n",
    "\n",
    "    k_string = \"\".join(song.metadata['K'])\n",
    "    k_num_matrix[row_ind,0] = np.array([char_to_num[k_string[j]] for j in range(k_len)])\n",
    "\n",
    "    m_string = \"\".join(song.metadata['M'])\n",
    "    m_num_matrix[row_ind,] = np.array([char_to_num[m_string[j]] for j in range(m_len)])\n",
    "\n",
    "    y_vals.append(char_to_num[part_string[part_len]])\n",
    "\n",
    "    # increase row index after every song\n",
    "    row_ind += 1\n",
    "\n",
    "# Convert y_vals to one_hot_encoded vectors\n",
    "y_data = to_categorical(y_vals, num_classes=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(817, 3)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_num_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_24 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 38)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 3, 256)       23296       input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 1, 256)       23296       input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 38, 256)      23296       input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 42, 256)      0           embedding_24[0][0]               \n",
      "                                                                 embedding_23[0][0]               \n",
      "                                                                 embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 42, 200)      365600      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 42, 336)      721728      lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 200)          429600      lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 91)           18291       lstm_24[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,605,107\n",
      "Trainable params: 1,605,107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod5 = LSTM_Builder4([200, 336, 200], 0.2, 50, \n",
    "                     256,vocab_length,\n",
    "                     part_num_matrix, k_num_matrix, m_num_matrix)\n",
    "\n",
    "mod5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod5.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use checkpoints to save training weights before the model finishes training\n",
    "weights_filepath = \"mod5_weights.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weights_filepath, monitor=\"loss\", verbose=0,\n",
    "    save_best_only=True, mode=\"min\")\n",
    "\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "817/817 [==============================] - 6s 8ms/step - loss: 3.8135\n",
      "Epoch 2/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.9237\n",
      "Epoch 3/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 2.8218\n",
      "Epoch 4/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.8044\n",
      "Epoch 5/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7978\n",
      "Epoch 6/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7866\n",
      "Epoch 7/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7879\n",
      "Epoch 8/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7839\n",
      "Epoch 9/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7878\n",
      "Epoch 10/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7897\n",
      "Epoch 11/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7830\n",
      "Epoch 12/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7890\n",
      "Epoch 13/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7778\n",
      "Epoch 14/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7822\n",
      "Epoch 15/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7827\n",
      "Epoch 16/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7846\n",
      "Epoch 17/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7931\n",
      "Epoch 18/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7817\n",
      "Epoch 19/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7822\n",
      "Epoch 20/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7779\n",
      "Epoch 21/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7719\n",
      "Epoch 22/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7811\n",
      "Epoch 23/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7834\n",
      "Epoch 24/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7768\n",
      "Epoch 25/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7633\n",
      "Epoch 26/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7459\n",
      "Epoch 27/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.7049\n",
      "Epoch 28/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.6027\n",
      "Epoch 29/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.4846\n",
      "Epoch 30/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 2.3810\n",
      "Epoch 31/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.2958\n",
      "Epoch 32/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.2299\n",
      "Epoch 33/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.1804\n",
      "Epoch 34/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.1498\n",
      "Epoch 35/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 2.1209\n",
      "Epoch 36/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.0974\n",
      "Epoch 37/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.0621\n",
      "Epoch 38/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.0209\n",
      "Epoch 39/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 2.0011\n",
      "Epoch 40/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 1.9707\n",
      "Epoch 41/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.9414\n",
      "Epoch 42/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.9125\n",
      "Epoch 43/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.8806\n",
      "Epoch 44/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.8677\n",
      "Epoch 45/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.8297\n",
      "Epoch 46/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.8153\n",
      "Epoch 47/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.8059\n",
      "Epoch 48/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.7698\n",
      "Epoch 49/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.7752\n",
      "Epoch 50/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.7205\n",
      "Epoch 51/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.7120\n",
      "Epoch 52/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.6973\n",
      "Epoch 53/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.6738\n",
      "Epoch 54/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.6646\n",
      "Epoch 55/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.6403\n",
      "Epoch 56/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.6256\n",
      "Epoch 57/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.6040\n",
      "Epoch 58/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.5925\n",
      "Epoch 59/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.5667\n",
      "Epoch 60/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.5479\n",
      "Epoch 61/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.5488\n",
      "Epoch 62/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.5242\n",
      "Epoch 63/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4919\n",
      "Epoch 64/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4863\n",
      "Epoch 65/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4726\n",
      "Epoch 66/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4562\n",
      "Epoch 67/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4344\n",
      "Epoch 68/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.4208\n",
      "Epoch 69/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3897\n",
      "Epoch 70/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3769\n",
      "Epoch 71/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3665\n",
      "Epoch 72/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3547\n",
      "Epoch 73/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 1.3312\n",
      "Epoch 74/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3284\n",
      "Epoch 75/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3079\n",
      "Epoch 76/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.3244\n",
      "Epoch 77/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.2753\n",
      "Epoch 78/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.2594\n",
      "Epoch 79/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.2446\n",
      "Epoch 80/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 1.2098\n",
      "Epoch 81/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.2074\n",
      "Epoch 82/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.1911\n",
      "Epoch 83/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.2094\n",
      "Epoch 84/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.2021\n",
      "Epoch 85/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.1529\n",
      "Epoch 86/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.1320\n",
      "Epoch 87/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.1214\n",
      "Epoch 88/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.0927\n",
      "Epoch 89/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.0902\n",
      "Epoch 90/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.0848\n",
      "Epoch 91/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.0619\n",
      "Epoch 92/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.0750\n",
      "Epoch 93/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.0474\n",
      "Epoch 94/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 1.0136\n",
      "Epoch 95/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 1.0009\n",
      "Epoch 96/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.9745\n",
      "Epoch 97/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.9550\n",
      "Epoch 98/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 5s 6ms/step - loss: 0.9604\n",
      "Epoch 99/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.9499\n",
      "Epoch 100/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.9229\n",
      "Epoch 101/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.9109\n",
      "Epoch 102/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.9007\n",
      "Epoch 103/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.8891\n",
      "Epoch 104/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.8562\n",
      "Epoch 105/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.8454\n",
      "Epoch 106/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.8406\n",
      "Epoch 107/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.8145\n",
      "Epoch 108/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.8154\n",
      "Epoch 109/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.8240\n",
      "Epoch 110/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.7783\n",
      "Epoch 111/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.7680\n",
      "Epoch 112/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.7579\n",
      "Epoch 113/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.7418\n",
      "Epoch 114/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.7095\n",
      "Epoch 115/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.7073\n",
      "Epoch 116/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.6885\n",
      "Epoch 117/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.6614\n",
      "Epoch 118/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.6628\n",
      "Epoch 119/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.6392\n",
      "Epoch 120/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.6132\n",
      "Epoch 121/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.6201\n",
      "Epoch 122/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.6144\n",
      "Epoch 123/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.6139\n",
      "Epoch 124/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5710\n",
      "Epoch 125/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5644\n",
      "Epoch 126/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5436\n",
      "Epoch 127/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5476\n",
      "Epoch 128/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5197\n",
      "Epoch 129/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.5119\n",
      "Epoch 130/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.5111\n",
      "Epoch 131/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4758\n",
      "Epoch 132/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4664\n",
      "Epoch 133/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4579\n",
      "Epoch 134/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4627\n",
      "Epoch 135/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4278\n",
      "Epoch 136/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4283\n",
      "Epoch 137/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.4256\n",
      "Epoch 138/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.4121\n",
      "Epoch 139/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3926\n",
      "Epoch 140/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3990\n",
      "Epoch 141/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3809\n",
      "Epoch 142/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3672\n",
      "Epoch 143/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3631\n",
      "Epoch 144/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.3433\n",
      "Epoch 145/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3452\n",
      "Epoch 146/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3243\n",
      "Epoch 147/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.3089\n",
      "Epoch 148/5000\n",
      "817/817 [==============================] - 4s 5ms/step - loss: 0.3003\n",
      "Epoch 149/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.2899\n",
      "Epoch 150/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2809\n",
      "Epoch 151/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.2800\n",
      "Epoch 152/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2718\n",
      "Epoch 153/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2611\n",
      "Epoch 154/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2490\n",
      "Epoch 155/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.2556\n",
      "Epoch 156/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2307\n",
      "Epoch 157/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2345\n",
      "Epoch 158/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2398\n",
      "Epoch 159/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2197\n",
      "Epoch 160/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2166\n",
      "Epoch 161/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.2039\n",
      "Epoch 162/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1838\n",
      "Epoch 163/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1871\n",
      "Epoch 164/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1787\n",
      "Epoch 165/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1715\n",
      "Epoch 166/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1762\n",
      "Epoch 167/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1617\n",
      "Epoch 168/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1693\n",
      "Epoch 169/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1676\n",
      "Epoch 170/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1572\n",
      "Epoch 171/5000\n",
      "817/817 [==============================] - 4s 6ms/step - loss: 0.1361\n",
      "Epoch 172/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1480\n",
      "Epoch 173/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1474\n",
      "Epoch 174/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1332\n",
      "Epoch 175/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1406\n",
      "Epoch 176/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1347\n",
      "Epoch 177/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1308\n",
      "Epoch 178/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1279\n",
      "Epoch 179/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1092\n",
      "Epoch 180/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1070\n",
      "Epoch 181/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0975\n",
      "Epoch 182/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0979\n",
      "Epoch 183/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.1047\n",
      "Epoch 184/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0917\n",
      "Epoch 185/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0922\n",
      "Epoch 186/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0985\n",
      "Epoch 187/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0903\n",
      "Epoch 188/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0866\n",
      "Epoch 189/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0784\n",
      "Epoch 190/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0760\n",
      "Epoch 191/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0761\n",
      "Epoch 192/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0718\n",
      "Epoch 193/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0685\n",
      "Epoch 194/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0682\n",
      "Epoch 195/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0659\n",
      "Epoch 196/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0620\n",
      "Epoch 197/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0652\n",
      "Epoch 198/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0641\n",
      "Epoch 199/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0611\n",
      "Epoch 200/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0606\n",
      "Epoch 201/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0658\n",
      "Epoch 202/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0651\n",
      "Epoch 203/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0575\n",
      "Epoch 204/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0556\n",
      "Epoch 205/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0625\n",
      "Epoch 206/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0559\n",
      "Epoch 207/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0533\n",
      "Epoch 208/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0509\n",
      "Epoch 209/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0446\n",
      "Epoch 210/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0460\n",
      "Epoch 211/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0440\n",
      "Epoch 212/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0399\n",
      "Epoch 213/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0432\n",
      "Epoch 214/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0401\n",
      "Epoch 215/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0391\n",
      "Epoch 216/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0388\n",
      "Epoch 217/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0355\n",
      "Epoch 218/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0352\n",
      "Epoch 219/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0366\n",
      "Epoch 220/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0359\n",
      "Epoch 221/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0343\n",
      "Epoch 222/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0358\n",
      "Epoch 223/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0311\n",
      "Epoch 224/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0364\n",
      "Epoch 225/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0320\n",
      "Epoch 226/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0318\n",
      "Epoch 227/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0321\n",
      "Epoch 228/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0308\n",
      "Epoch 229/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0305\n",
      "Epoch 230/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0277\n",
      "Epoch 231/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0282\n",
      "Epoch 232/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0280\n",
      "Epoch 233/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0280\n",
      "Epoch 234/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0270\n",
      "Epoch 235/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0243\n",
      "Epoch 236/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0238\n",
      "Epoch 237/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0248\n",
      "Epoch 238/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0231\n",
      "Epoch 239/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0214\n",
      "Epoch 240/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0220\n",
      "Epoch 241/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0224\n",
      "Epoch 242/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0232\n",
      "Epoch 243/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0220\n",
      "Epoch 244/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0220\n",
      "Epoch 245/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0215\n",
      "Epoch 246/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0204\n",
      "Epoch 247/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0192\n",
      "Epoch 248/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0212\n",
      "Epoch 249/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0215\n",
      "Epoch 250/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0208\n",
      "Epoch 251/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0209\n",
      "Epoch 252/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0187\n",
      "Epoch 253/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0217\n",
      "Epoch 254/5000\n",
      "817/817 [==============================] - 7s 8ms/step - loss: 0.0191\n",
      "Epoch 255/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0193\n",
      "Epoch 256/5000\n",
      "817/817 [==============================] - 7s 8ms/step - loss: 0.0181\n",
      "Epoch 257/5000\n",
      "817/817 [==============================] - 6s 8ms/step - loss: 0.0175\n",
      "Epoch 258/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0175\n",
      "Epoch 259/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0179\n",
      "Epoch 260/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0184\n",
      "Epoch 261/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0172\n",
      "Epoch 262/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0180\n",
      "Epoch 263/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0155\n",
      "Epoch 264/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0151\n",
      "Epoch 265/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0156\n",
      "Epoch 266/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0133\n",
      "Epoch 267/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0137\n",
      "Epoch 268/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0139\n",
      "Epoch 269/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0123\n",
      "Epoch 270/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0147\n",
      "Epoch 271/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0135\n",
      "Epoch 272/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0132\n",
      "Epoch 273/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0140\n",
      "Epoch 274/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0123\n",
      "Epoch 275/5000\n",
      "817/817 [==============================] - 5s 6ms/step - loss: 0.0139\n",
      "Epoch 276/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0172\n",
      "Epoch 277/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0186\n",
      "Epoch 278/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0208\n",
      "Epoch 279/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0173\n",
      "Epoch 280/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0174\n",
      "Epoch 281/5000\n",
      "817/817 [==============================] - 6s 7ms/step - loss: 0.0159\n",
      "Epoch 282/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0142\n",
      "Epoch 283/5000\n",
      "817/817 [==============================] - 5s 7ms/step - loss: 0.0129\n",
      "Epoch 284/5000\n",
      "817/817 [==============================] - 6s 8ms/step - loss: 0.0128\n",
      "Epoch 285/5000\n",
      "817/817 [==============================] - 7s 9ms/step - loss: 0.0124\n",
      "Epoch 286/5000\n",
      "400/817 [=============>................] - ETA: 3s - loss: 0.0140"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-a035beaf6f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m mod5.fit([part_num_matrix, k_num_matrix, m_num_matrix],\n\u001b[1;32m      2\u001b[0m          \u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          epochs=5000, batch_size=100, shuffle=True, callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod5.fit([part_num_matrix, k_num_matrix, m_num_matrix],\n",
    "         y_data, \n",
    "         epochs=5000, batch_size=100, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up testing data\n",
    "my_session = tf.Session()\n",
    "mod5.reset_states()\n",
    "\n",
    "starter = song_list[total_songs_train]\n",
    "start_ind = total_songs_train\n",
    "end_ind = len(song_list)\n",
    "seq_len = 40\n",
    "\n",
    "input_part = np.zeros((1, part_len))\n",
    "sequences = input_part\n",
    "input_k = np.zeros((1, k_len))\n",
    "input_m = np.zeros((1, m_len))\n",
    "\n",
    "for i in range(start_ind,start_ind+1):\n",
    "    song = song_list[i]\n",
    "    \n",
    "    part_string = \"\".join(song.part)\n",
    "    k_string = \"\".join(song.metadata['K'])\n",
    "    m_string = \"\".join(song.metadata['M'])\n",
    "    \n",
    "    input_part[i-start_ind,] = np.array([char_to_num[part_string[0:part_len][j]] for j in range(part_len)])\n",
    "    input_k[i-start_ind,] = np.array([char_to_num[k_string[j]] for j in range(k_len)])\n",
    "    input_m[i-start_ind,] = np.array([char_to_num[m_string[j]] for j in range(m_len)])\n",
    "\n",
    "# Starting string:\n",
    "beginning = str(starter)\n",
    "result = []\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "for i in range(seq_len):\n",
    "    prediction = mod5.predict([input_part, input_k, input_m])\n",
    "    \n",
    "    # Sample from output of probabilities\n",
    "    sample = tf.random.categorical(prediction, num_samples=1)\n",
    "    sample = tf.squeeze(sample, axis=-1)\n",
    "    numeric_pred = my_session.run(sample)[0]\n",
    "    \n",
    "    # Pass the prediction, along with the hidden state, back to the model\n",
    "    sequences = np.append(sequences, numeric_pred)\n",
    "    input_part = sequences[i:part_len+i].reshape(1, part_len)\n",
    "    \n",
    "    # Text predictions\n",
    "    text_val = num_to_char[numeric_pred]\n",
    "    result.append(text_val)\n",
    "\n",
    "result = \"\".join(result)\n",
    "print(beginning)\n",
    "print(\"______\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
